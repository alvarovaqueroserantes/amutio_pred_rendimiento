{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606aa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras filas SEMANAL:\n",
      "       fecha  mes  semana_del_año   parcela variedad  tam_parcela_ha  \\\n",
      "0 2021-02-07    2               5  Agria_p1    Agria         2.74908   \n",
      "1 2021-02-14    2               6  Agria_p1    Agria         2.74908   \n",
      "2 2021-02-21    2               7  Agria_p1    Agria         2.74908   \n",
      "3 2021-02-28    2               8  Agria_p1    Agria         2.74908   \n",
      "4 2021-03-07    3               9  Agria_p1    Agria         2.74908   \n",
      "5 2021-03-14    3              10  Agria_p1    Agria         2.74908   \n",
      "6 2021-03-21    3              11  Agria_p1    Agria         2.74908   \n",
      "7 2021-03-28    3              12  Agria_p1    Agria         2.74908   \n",
      "8 2021-04-04    4              13  Agria_p1    Agria         2.74908   \n",
      "9 2021-04-11    4              14  Agria_p1    Agria         2.74908   \n",
      "\n",
      "   temp_media     lluvia  fertilizante       riego  semana_cultivo  \n",
      "0   10.698013  23.756980      9.416613  269.968066               1  \n",
      "1   11.796587  38.522782      7.884578  299.325139               2  \n",
      "2   14.645090   7.791564      6.080660  310.443180               3  \n",
      "3   10.343628  21.968612     10.342737  336.923329               4  \n",
      "4   16.653055  12.591170      3.920234  296.503461               5  \n",
      "5   15.618084  23.456978      2.355440  424.053280               6  \n",
      "6   17.972252  11.919342      5.917514  352.615460               7  \n",
      "7   20.092999  22.450241      4.536181  341.254773               8  \n",
      "8   17.993790  22.804361      4.721512  366.457803               9  \n",
      "9   13.680995   5.430347      7.034360  456.876808              10  \n",
      "\n",
      "Primeras filas COSECHAS:\n",
      "  fecha_cosecha   parcela variedad  tam_parcela_ha  rendimiento_ton_ha  \\\n",
      "0    2021-06-06  Agria_p1    Agria        2.749080               76.29   \n",
      "1    2022-06-05  Agria_p1    Agria        2.749080               72.06   \n",
      "2    2023-06-04  Agria_p1    Agria        2.749080               76.38   \n",
      "3    2024-06-02  Agria_p1    Agria        2.749080               77.39   \n",
      "4    2025-06-01  Agria_p1    Agria        2.749080               79.43   \n",
      "5    2021-06-06  Agria_p2    Agria        3.901429               72.30   \n",
      "6    2022-06-05  Agria_p2    Agria        3.901429               72.41   \n",
      "7    2023-06-04  Agria_p2    Agria        3.901429               78.15   \n",
      "8    2024-06-02  Agria_p2    Agria        3.901429               78.18   \n",
      "9    2025-06-01  Agria_p2    Agria        3.901429               82.33   \n",
      "\n",
      "   mes_cosecha  \n",
      "0            6  \n",
      "1            6  \n",
      "2            6  \n",
      "3            6  \n",
      "4            6  \n",
      "5            6  \n",
      "6            6  \n",
      "7            6  \n",
      "8            6  \n",
      "9            6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# generar 10 parcelas por variedad\n",
    "variedades = {\n",
    "    \"Agria\": {\"mes_siembra\": 2, \"ciclo_semanas\": 18},\n",
    "    \"Monalisa\": {\"mes_siembra\": 1, \"ciclo_semanas\": 16},\n",
    "    \"Spunta\": {\"mes_siembra\": 12, \"ciclo_semanas\": 15}\n",
    "}\n",
    "\n",
    "parcelas = {}\n",
    "for variedad, vinfo in variedades.items():\n",
    "    for i in range(1, 11):\n",
    "        parcela_id = f\"{variedad}_p{i}\"\n",
    "        parcelas[parcela_id] = {\n",
    "            \"variedad\": variedad,\n",
    "            \"tam_ha\": np.random.uniform(2,4),\n",
    "            \"ciclo_semanas\": vinfo[\"ciclo_semanas\"],\n",
    "            \"mes_siembra\": vinfo[\"mes_siembra\"]\n",
    "        }\n",
    "\n",
    "# fechas semanales\n",
    "fechas = pd.date_range(\"2020-07-01\", \"2025-07-01\", freq=\"W\")\n",
    "\n",
    "data_semanal = []\n",
    "data_cosechas = []\n",
    "\n",
    "for parcela, info in parcelas.items():\n",
    "    variedad = info[\"variedad\"]\n",
    "    tam_ha = info[\"tam_ha\"]\n",
    "    ciclo_semanas = info[\"ciclo_semanas\"]\n",
    "    mes_siembra = info[\"mes_siembra\"]\n",
    "    \n",
    "    rendimiento_acumulado = 0\n",
    "    semana_cultivo = 0\n",
    "    \n",
    "    for fecha in fechas:\n",
    "        mes_actual = fecha.month\n",
    "        semana_del_año = fecha.isocalendar().week\n",
    "        \n",
    "        # iniciar campaña anual\n",
    "        if mes_actual == mes_siembra and semana_cultivo == 0:\n",
    "            semana_cultivo = 1\n",
    "            rendimiento_acumulado = 0\n",
    "            \n",
    "        if semana_cultivo > 0:\n",
    "            # clima según época\n",
    "            if mes_actual in [12,1,2]:\n",
    "                temp_media = np.random.normal(13,2)\n",
    "                lluvia = np.clip(np.random.normal(20,10), 0, 50)\n",
    "                riego = np.clip(np.random.normal(300,50), 150,450)\n",
    "            elif mes_actual in [3,4,5]:\n",
    "                temp_media = np.random.normal(17,3)\n",
    "                lluvia = np.clip(np.random.normal(15,8), 0,40)\n",
    "                riego = np.clip(np.random.normal(400,70), 250,550)\n",
    "            elif mes_actual in [6,7,8]:\n",
    "                temp_media = np.random.normal(27,3)\n",
    "                lluvia = np.clip(np.random.normal(5,3), 0,15)\n",
    "                riego = np.clip(np.random.normal(600,80), 400,800)\n",
    "            else:\n",
    "                temp_media = np.random.normal(20,3)\n",
    "                lluvia = np.clip(np.random.normal(15,10), 0,50)\n",
    "                riego = np.clip(np.random.normal(400,70), 250,550)\n",
    "            \n",
    "            # fertilizante\n",
    "            if semana_cultivo <= 4:\n",
    "                fertilizante = np.clip(np.random.normal(10,2),5,15)\n",
    "            else:\n",
    "                fertilizante = np.clip(np.random.normal(5,1.5),2,8)\n",
    "            \n",
    "            # rendimiento\n",
    "            rendimiento_acumulado += (\n",
    "                0.3 * fertilizante +\n",
    "                0.05 * riego/100 +\n",
    "                np.clip(temp_media - 15, 0, 10)*0.4 -\n",
    "                0.1 * (30 - lluvia)/30\n",
    "            )\n",
    "            \n",
    "            data_semanal.append({\n",
    "                \"fecha\": fecha,\n",
    "                \"mes\": mes_actual,\n",
    "                \"semana_del_año\": semana_del_año,\n",
    "                \"parcela\": parcela,\n",
    "                \"variedad\": variedad,\n",
    "                \"tam_parcela_ha\": tam_ha,\n",
    "                \"temp_media\": temp_media,\n",
    "                \"lluvia\": lluvia,\n",
    "                \"fertilizante\": fertilizante,\n",
    "                \"riego\": riego,\n",
    "                \"semana_cultivo\": semana_cultivo\n",
    "            })\n",
    "            \n",
    "            semana_cultivo += 1\n",
    "            \n",
    "            if semana_cultivo > ciclo_semanas:\n",
    "                # fijar mes de cosecha según variedad\n",
    "                if variedad == \"Agria\":\n",
    "                    mes_cosecha = 6  # junio\n",
    "                elif variedad == \"Monalisa\":\n",
    "                    mes_cosecha = 5  # mayo\n",
    "                elif variedad == \"Spunta\":\n",
    "                    mes_cosecha = 4  # abril\n",
    "                else:\n",
    "                    mes_cosecha = fecha.month  # fallback\n",
    "\n",
    "                rendimiento_ciclo = 25 + rendimiento_acumulado + np.random.normal(0,2)\n",
    "                \n",
    "                data_cosechas.append({\n",
    "                    \"fecha_cosecha\": fecha,\n",
    "                    \"parcela\": parcela,\n",
    "                    \"variedad\": variedad,\n",
    "                    \"tam_parcela_ha\": tam_ha,\n",
    "                    \"rendimiento_ton_ha\": np.round(rendimiento_ciclo,2),\n",
    "                    \"mes_cosecha\": mes_cosecha\n",
    "                })\n",
    "                \n",
    "                semana_cultivo = 0  # parar ciclo hasta siguiente año\n",
    "\n",
    "# dataframes\n",
    "df_semanal = pd.DataFrame(data_semanal)\n",
    "df_cosechas = pd.DataFrame(data_cosechas)\n",
    "\n",
    "# guardar\n",
    "df_semanal.to_csv(\"datos_semanales.csv\", index=False)\n",
    "df_cosechas.to_csv(\"datos_cosechas.csv\", index=False)\n",
    "\n",
    "print(\"\\nPrimeras filas SEMANAL:\")\n",
    "print(df_semanal.head(10))\n",
    "\n",
    "print(\"\\nPrimeras filas COSECHAS:\")\n",
    "print(df_cosechas.head(10))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# cargar histórico\n",
    "historico = pd.read_csv(\"datos_semanales.csv\", parse_dates=[\"fecha\"])\n",
    "\n",
    "fecha_max = historico[\"fecha\"].max()\n",
    "fechas_futuras = pd.date_range(fecha_max + pd.Timedelta(days=1), periods=28, freq=\"D\")\n",
    "\n",
    "parcelas = historico[\"parcela\"].unique()\n",
    "\n",
    "futuro = []\n",
    "\n",
    "for parcela in parcelas:\n",
    "    variedad = historico[historico[\"parcela\"]==parcela][\"variedad\"].iloc[-1]\n",
    "    tam_parcela = historico[historico[\"parcela\"]==parcela][\"tam_parcela_ha\"].iloc[-1]\n",
    "    \n",
    "    for fecha in fechas_futuras:\n",
    "        mes = fecha.month\n",
    "        \n",
    "        # temperatura\n",
    "        if mes in [12,1,2]:\n",
    "            temp_max = np.random.normal(17,2)\n",
    "            temp_min = np.random.normal(8,2)\n",
    "        elif mes in [6,7,8]:\n",
    "            temp_max = np.random.normal(32,3)\n",
    "            temp_min = np.random.normal(20,2)\n",
    "        else:\n",
    "            temp_max = np.random.normal(24,3)\n",
    "            temp_min = np.random.normal(12,2)\n",
    "        temp_media = (temp_max + temp_min) / 2\n",
    "        \n",
    "        # lluvia\n",
    "        lluvia = np.clip(np.random.normal(2,2), 0,20)\n",
    "        prob_lluvia = np.clip(np.random.normal(30,10), 0,100)\n",
    "        \n",
    "        # humedad\n",
    "        humedad_rel = np.clip(np.random.normal(65,10),30,100)\n",
    "        \n",
    "        # viento\n",
    "        viento_vel = np.clip(np.random.normal(15,5),0,40)\n",
    "        viento_dir = np.random.randint(0,360)\n",
    "        \n",
    "        # radiación solar\n",
    "        radiacion = np.clip(np.random.normal(15,5),5,30)  # MJ/m2/día\n",
    "        \n",
    "        # presión\n",
    "        presion = np.clip(np.random.normal(1013,5),1000,1030)\n",
    "        \n",
    "        # ET0\n",
    "        et0 = np.clip(np.random.normal(4,1),2,8)\n",
    "        \n",
    "        # sugerencias riego/ferti\n",
    "        if temp_media > 25:\n",
    "            riego_sug = np.clip(np.random.normal(25,5),15,35)\n",
    "            ferti_sug = np.clip(np.random.normal(0.5,0.1),0.3,0.7)\n",
    "        else:\n",
    "            riego_sug = np.clip(np.random.normal(15,4),5,25)\n",
    "            ferti_sug = np.clip(np.random.normal(0.3,0.05),0.1,0.5)\n",
    "        \n",
    "        futuro.append({\n",
    "            \"fecha\": fecha,\n",
    "            \"parcela\": parcela,\n",
    "            \"variedad\": variedad,\n",
    "            \"tam_parcela_ha\": tam_parcela,\n",
    "            \"temp_max\": temp_max,\n",
    "            \"temp_min\": temp_min,\n",
    "            \"temp_media\": temp_media,\n",
    "            \"lluvia\": lluvia,\n",
    "            \"prob_lluvia_%\": prob_lluvia,\n",
    "            \"humedad_relativa_%\": humedad_rel,\n",
    "            \"viento_vel_kmh\": viento_vel,\n",
    "            \"viento_dir_deg\": viento_dir,\n",
    "            \"radiacion_MJ_m2\": radiacion,\n",
    "            \"presion_hPa\": presion,\n",
    "            \"et0_mm\": et0,\n",
    "            \"riego_sugerido_mm\": riego_sug,\n",
    "            \"fertilizante_sugerido_kg\": ferti_sug\n",
    "        })\n",
    "        \n",
    "df_futuro = pd.DataFrame(futuro)\n",
    "df_futuro.to_csv(\"prediccion_meteo_4semanas_completa.csv\", index=False)\n",
    "\n",
    "print(\"✅ CSV `prediccion_meteo_4semanas_completa.csv` generado con variables meteorológicas extendidas día a día.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60d4b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros Stacking:\n",
      "{'stack__final_estimator__alpha': 10.0}\n",
      "Mejor R2 validación cruzada: 0.923\n",
      "RMSE holdout: 2.51\n",
      "R2 holdout: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\Users\\alvar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alvar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 550, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\alvar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1028, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\alvar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 1540, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaStJREFUeJzt3QmcTuX///GPfRn7viSyRiFbWUOK+PJFi8LXUiIiWyS/tFBZKm1atCIpbSgpJBRSyZZKyhZ9E9mT7Of/eF+/37n/94x7Zu5xxgwzr+fjcZj7rNc597lnrs+5Ptd1Z/A8zzMAAAAACCBjkI0BAAAAQAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwA4Cx58MEHLUOGDGf9ON27d7cyZcrY+Wjy5MnuGm3dujXJ2zZp0sQuvfTSRNfTvnUMHSulvfPOO1agQAE7dOiQnS/86/X444+ndlEQBb1X/fr1Oyc+A/fcc49dccUVZ/UYOLcRWACIVcH79ttv7Xz1/PPPp0rlMS2pVq2aXXjhheZ5XrzrNGjQwIoWLWonTpxI0bKdb06ePGkPPPCA3XnnnZYrVy4378cff7SsWbPaLbfcctr6+/fvt+LFi7uK2alTp2It++6779w2F110kWXPnt3t77LLLrO7777bNm/efFqgqc+yP2XOnNlKlSplN998szs+gvnzzz9twIABdvHFF1uOHDmsSJEidvnll9uwYcNiBZBvvvmmPfXUU5aeDBw40NauXWsffvhhahcFqYTAAkCaca4FFiNGjLB//vnHziedO3e27du325IlS+J98rl8+XK76aabXIU1qC5durhrVLp0aUtrZs+ebRs2bLBevXqF5lWpUsWGDh3q7tPPP//8tKe9qrS++OKLljHj///z/PLLL1vNmjXtk08+seuuu84mTJhgjz32mAvwXn/9dVfBVRATLlu2bDZ16lQ3vfLKKy7Y+Oyzz6x+/fr2+++/p8DZp0179+612rVru+v+r3/9y5555hkbPHiwlS9f3l544QXbvXv3ORlY6POlz5k+b2dTsWLFrG3btrR2pWPB/yoAQCo7fPiw5cyZ0841qngnR+U7JXXq1MmGDx/uKkVXXnnlacvfeust15qhACSIv//+22JiYixTpkxuSosmTZrkKv8lS5aMNf++++6zt99+226//XbXEqEWDAVrL730kg0aNMi1RPi+/PJL69Onj9vPRx99ZLlz5461r/Hjx9sjjzxy2rF13/3nP/+JNa9u3brWunVrmzNnjvXs2TPZzzc9ePXVV23btm22bNkyF6SFO3jwoHsvz0VquVJLV0ro0KGD3Xjjja4lrWzZsilyTJw7aLEAEC895VTKhf6QqkKin1VJeu6559zydevW2VVXXeUqiHoipspopPSqL774wlWiChYsaHny5LGuXbvavn37IrY4XHLJJe5pa4kSJaxv374uPSRSXv3KlStdxVcBxf/8z/+4PgY//PCDewrsp4BoXf8p45AhQ6xq1aruHFSGli1buib7cIsXL3bbKS9elbULLrjA/TFu1qyZbdy48bTyfv3119aqVSvLnz+/uwZKI3r66acT7GOhyqaumdIndJ56gq0nndGaNWuWO3+VS//PnDkz4npKpdHTUl1PravUJb0Hka57OKXM6Lq+9957dvz48dOW6z0uV66cS9f59ddf7Y477rBKlSq5lBC9v6pQxO0v4d8Hem+0vs5d1zZ8Wfg2H3zwgXsarHtA10jHe+ihh057Ku/TvaBKnsqgVKGJEydGdS1/+uknu+GGG1wfCF0jPYmOm8KhazBy5EirUKGCW0fn2LBhQ/v0008T3PeRI0ds7ty5dvXVV5+2TPvRe67WjDFjxrhjqFVD137UqFGx1tWxdX2mTZt2WlDh70vXJprgTE+TJSnB7pNPPuk+27q2jRs3tu+//z7WcgVG+j2hCqTKomPceuuttmfPnljr/fXXXy5NRp9Tvae6B6655hpbtWrVaZ+pa6+91vLmzes+2zqmKvHROHr0qEs9U+uBjqHrqVQxzY/UJ8H/LGldfU70fiVm06ZN7lorSItLv1f8yrt+9yiA02fE/33k94M6duyY3X///VarVi13nvrd0ahRI1u0aFHEz7F+p+h3l/ZduHBhd30SS1l9+OGHXauXWrfi62Ph/37/73//a+3atXM/a//6XRn3s6b3U60dOsd8+fJZt27d3O/PSP02/Hten2OkP+fXozQAKU5/YFQJV2Xz0UcfdRUc/VHWH8N7773XPblWeoYqcwoY6tWr5yp34bS+/hipoq3KlCpV+oPrV+RFy1SJ0h8lPaH111uxYoWrWGTJkiXWHzmVSTnjeiqrSrP+kPu57CqXaL7oyZkqEar0qmw7d+506SaqtCjnXBXYcGPHjnV/lPUH9sCBA+68dZ6q9PhUsVSwpZx45VurQrV+/Xr3VFmv46NzUiXm3//+t6vgKV1GlW1VIBRIJWT+/Pl2/fXXu2BEFVJdB+Xd+5X0cAoi9Adfy/v3729btmyxZ5991lavXn3a9YxL56qK7rx589w5+hRIqmKpSpHovdETdb0PKoMqLzo/vRe6rnFbkXSeqrhoe7VYxEfl1vuoFBP9v3DhQreNnggrBSicAiUFd3pK2rFjRxcU6v7Rk2NVcOOjINRvTVAKku5nbasK1vvvv2/t27cP3Ze61rfddpvLo1cZVKlThVgV4/go2FEFUilMkWhblVf7VmqSrqsqYipHeEuczl3XM9J7nBg/LUefYX0G1AdAgVH4e5oQpfsoINB9qUBJFVwFxboP/M+WPgfat+4zfQZ0XdXyov+/+uqr0Oe7d+/eLljV7wLdv7p3ly5d6j4z/jXSuepzrQq3AgR9Bv1AXKl5uv7x0edHnyntU/du5cqVXTkVGP3888/u8x9O682YMcPdkwrYlNKkz5YeougaxUdBlq6nUsxUuY6Pfgfpd8dvv/3myiB+PxvdQ0pP0/uvliNdY7WEtGjRwr755ptYLVY9evRwnwddF92D6teka6Frq0A4vhTM0aNHu99xibVM6Vx0XD0oUPrSggULXCuYgnl9jvxr26ZNG1c2zVPqne7V+M5fwZK21+8ZtcAhnfEAwPO8SZMmqbeut2LFitC8bt26uXmjR48Ozdu3b5+XI0cOL0OGDN706dND83/66Se37gMPPHDaPmvVquUdO3YsNP/RRx918z/44AP3eteuXV7WrFm95s2beydPngyt9+yzz7r1XnvttdC8xo0bu3kTJ0487RwuueQStzyuI0eOxNqvbNmyxcuWLZs3atSo0LxFixa5fVeuXNk7evRoaP7TTz/t5q9bt869PnHihHfRRRd5pUuXdtcj3KlTp0I/61rE/TV7+PDh08rXokULr2zZsl5iLrvsMq948eLe/v37Q/Pmz5/vjqGy+JYsWeLmTZs2Ldb2c+fOjTg/rr1797pr07Fjx1jz77nnHrf9hg0b4j2X5cuXu3Vef/310+6Dhg0bumsXzl+m98MXab+33367lzNnTvdexr0Xxo8fH5qn903XqUiRIqF7TvvWejqWr1mzZl7VqlVj7U/vXf369b0KFSqE5lWvXt3717/+5SXVK6+8EuueieSPP/7w8ufP79Zr167dacvXrl3rlg0cOPC0ZXv27PH+/PPP0BR+v/qf27hTyZIlvZUrVyZadv966XP+22+/heZ//fXXbv6gQYMSfK/eeustt94XX3wRmpc3b16vb9++8R5T117XXZ+F8M+Q9q/P2jXXXJNgmadOneplzJjR3fvh9HtCZVm2bFlonl7r983GjRtPu9YTJkxI8Dh6zwoXLuzWvfjii73evXt7b775ZqzPpE/3Tfjn0qfPQPj7Jfo9UrRoUe/WW28NzVu4cKE7Tv/+/U/bR/g10jr+tb3rrrvcdZg8eXKs9SN9Bvz7JPx3oNSoUcP9zva9//77br2nnnoqNE+/T6+66qrT9unT73L9HkX6QyoUgETpSZlPLQ9KfdGTVT0l9mmelsUdoUb0BDH8Cbmeeulp/ccff+xe6ymZnu4qVSK806qetqnpXSkF4ZS6EGlUnfhofX+/ekKnp6V6eqgyx03FEO07PFdaaQrin5ue+qsFQOXVOYdLbHhZpZT49ERTT5XVcqJ963V8duzYYWvWrHFPCfVEMPzJt54Ah3v33XfdOlqm/fuTngTrvCOlXIRTapdaAZQW5LcsqP4yffp095S0YsWKp52L0nl0XZWGomsS6brq/YwmZSd8v3qaq7LrPdATfKUvhdN9pNYZn943vd61a5drNYhEqXF6Oq7719+/JpVfT29/+eUXlx4iOhc9fde8pPBTgXQt46MWHb9Vp3nz5qct15Pt8Cfd4ZR6pNYff4qbwqW0GbUmaFLLk55eaz96X/UEPxpqvQnvH6IWAz3Z9j+3cd8rtWroOvppQuH3gK6jWvzi6ziue1vXWH18dO3890T3n1IRlU4Zd6SsuPe8Win0ND38nldrh8S959UyqqfqPqUx6ndNpN9f4dRSoxQgtcCotUwttSqzUruUkpbQaGo+fQb83y86J92PaonQZyv8mqnlTL9P1HoTV9zfMzquWoPUqvTGG28k2JoSl84lnD5r4ddBKWL6/R3e+qHfpwm1sOq+D+/IjvSDwAJAgvy83nCqtCo1I+4fN82PlMOv/PRwquAohcjPq1dalKiiH05/fFWB8pf7VNlJSidJ/fFWOoLKoSCjUKFC7pyUHx6pMq/hVsP5lUP/3JRnLdF8h0JcSg9QpUaBmSpbKof6iEhCgYV/DeJey0jXTRU07UuVnfDKpyYNh6lKd2KUDqVKnZ8nrZQnvV/hnbY1yoxSlJTLHn5d1S8m0rnETZGLjyrySkXS/aTKnvbpd0SOu1+lsYWnD4kf+MT33RjqL6OKmDpRx70+fiXOv0bq86Dz0T6V564RnXTfRCuhiqbSZf744w9XIdZx4352/D4Vkb4DQ++Lgob4Rt9R5VX3mSYFLQruFcDr+qlzfjQi3Wu6DuHXVZVipf6pwq0gQ9fQf5/D3yulEyrdS/eKAhSlmIVXXv3ATRXiuO+J0obUTyKhz4e2130Td1v/Xoh7z8f9jPuf88T6IIl+dynlT8G+UjaVRuWn+CmlKRpTpkxxwYzfb0fb6wFK+Dnq94zub/UBiiZtTX3f1KdCKVZBfr/HvQ763aNzjpvaqIcICd33KfEdPjj30McCQILie8Ic3/xontgFFf6UNBrKN1YlUjn3eqqoP9R64qYWh0hPQc/WuamioKeveqr6xBNPuEqWAiQ9AVbgk9AT2aTQfhRUqD9MJHErEpEoD18Ve3XW1hNZ/a/rov4UPvVpUQ68rqP61mh9VSa0TqRzieZ9UyVeLTgKKFSp11NlVX70JFd9BJLjGvn7UB8atVBE4lea1LdI75sq8urjokqu3is9qQ5vyYvLz9NXBS1S/wj101BFUP1f1EKm1iSdn/onhJdBLTJxO0yLrlFSO2KrHApC9fQ/uajVR0GnAi71DdBDA11fdTAOf6+0np6Ea7ABXUf1lRk3bpzr56D+A/66mh/exyBcpJYbn7ZX4KfPVST6rCX3Z1z3ugIXTRpsQIGYPnMJ3ReiFgV1nFaLkK6bPqsqj/rb+A8tkkr9hdTqo35UutbRBCNytkZk032vBw1IfwgsAJx1eprYtGnT0Gs9gdXTPqVliP8dBnr6Fz48odKjlHIUaWSdSOJ7QqZOozp+3KeJqsSeyR8/P4VCFb5oyybqqK0nr0pbCX9imlhqUvg1ipSSo+sWt3x6Oq3KRlKDMJ9aIDRikp6EqrO7Uk2UVuKPLORfVz1hVmfP8HSYuCN5JYU69CsVRhXO8OFudR9EotQaf+han5/qE9+3kfv3mNI7onn/VElT5V+T7l2VS0/cE6pAKnj0y60Kbzil46kFQU+jFTypZUJP/VUp1jEUpInOSR23NZqWUrPiDlt7JpRyE+23gEe613Rt/euqyqO+G0ODLvgd+uPbTvTUW52lNakFQZ22NfqaAgv/M6WAMimfKZ+2V4qSAvfUeFKue0pP+vV7LZrfR1pf93j4OnFTnnROSmNTq1BigYKCULUK6X5RUKf3JdIoYmdCv3v0OyrusN6RRsrz6b6vXr16shwf5xdSoQCcdXoKGz50qdIIVMFRhUJUkdCTe6UUhD8xVCCg1AA9DYyGKmKRKrV6Khf3SaQqyn4efVKpQqR0Dw3nGvd4CT3x9J8Ohq+j89NT/8SoUqYnuUqhCE+XUDpM3G9T1hNLVV7VOhOXrnu0FX+lPel9U58FfXFb3O+uiHRdlYoR37Cw0Yh0jRRgaijiSHQ+6j8Qvq5eq1VGrQCR6AmxKmBaL7wi6NO5+uIOm6qn5qrExR3CNC4dW/d0pGFBdZ+rn47+9yt/qpyrRUH57uHfaK4Ku66nUsEiBQRJecKuoEBBaLQVPo2kFP4Z0ahA6ifhf24jvVcS90vhVP64aUx6DxRY+ddR10sVaaV2RTrP8PckEt3zKqu+TDAupewlNApZUuj8I+1L10b3Snhaon4fRUrfinTdtF99l0k4jVKldXRvRPO+K7VKrZ8aaUujOCXXl3OqVU+/B8KvrVqI/GHH49I5q+Ul7vd8IH2gxQLAWafKnp4k6o+/KjaqJOq7ADQ8pKgSqLxv/QHV0zbN99erU6fOaV/0FR9VThS0aAx3Vf5UedFTdqX16Mmwngbrj52GoVTKwpl+eZPSqHQc/fFWZV/7VcVfHYuV562njJEo112VTW2nyroqUPpjrXJGquDGpVQJBVm6dkrr0pNMVeQ1fG14ZUxpMtq/1ld6hI6rp/N6kqyASh081RqRGO1HlV2lAanlQ8MKh9N11bCbSoFSB3JVjNRSktBwnYnR+6Mnv2oJUZqQnujqGPFVoFU5VUqN8v6VkqIvntM5K5hNaEhdVYp0HdWaoE6puhfUMqNz0BCh/nec6LwUhOje0lNjBQr+sKkJUfqWrruuR/h3U+hbzRUs6B7wh7T1K6F6X3SN9f9dd93l5it9SOktSjtTqo2CO7WG6DOlQEH3se6p8JYkUXCilBu/Eqjro/Qt/RypM3Ak+gzpGmmwBQUAChj03uq7IfzWBX8YalU81aKiNKe4rUvqIK/7SPecghoFZ7ouGq7Yb+3SZ0ppZgpadD/rM6X9KVjQ03IdSy1+8dF3LGi4YAVmWl+tdQpo9JnUfH0m4xueNSl0L+qa673zg0dV5F977TX3nvv9pUTLdT9q2GT9HtN5633X50atFdqHPs+6XnpvdK+Ff47VyqrzUgCqz66fXqbhZrUs0j2ojvP6vKo1WNdbwWFCn4NoKGVL/WJ0T6qVQvefWl31+ydSy4zeW31e9Q3cSIdSe1gqAOf2cLMxMTGnrathPjW0a1waWjF8aE5/n59//rnXq1cvN7Rmrly5vM6dO7vhMuPS8LIawjFLlixu6MU+ffqcNpxrfMf2h4LU8XPnzu2O6w89qyFFNQyjhmrVEJoNGjRww6JqefjwtP5ws++++26iQzXK0qVL3TCYOp6uU7Vq1WINVxlpuNkPP/zQrZc9e3avTJky3rhx49xwunGHXI2Phn7UMI4aDrZKlSrejBkz3PsUaVjLl156yQ0bqXNWGTW86t133+39/vvvXrSGDh3qytahQ4fTlum9ueWWW7xChQq591VDhWrYYZVFZUro3oq7LPzcNTRo3bp1XblLlCjhyjxv3jy3nt6juPfCt99+69WrV89dUx1b91E079+mTZu8rl27esWKFXP3nIZjbd26tffee++F1nn44Ye9yy+/3MuXL58rj+7PRx55JNbwyfHRe6Nhmbdt2xaa17ZtW3ev/PrrrxG30fF1LcO3kdWrV7uyXnjhhW6oVP9+030dPmxqfMPN5smTxw2xu2DBgkTL7V+vxx57zA3lW6pUKXe/NWrUyA3LGk7D0bZv395dHw0pe+ONN7r7K3zoaQ2tqvtIQ/f6nxX9/Pzzz592bJ3ndddd5xUsWNAdU++n7r3PPvss0XLrPdHnSfeEttXvG93/I0eO9A4cOBBxeNZwce/bSL777jt3LjVr1vQKFCjgZc6c2f1e0XmvWrUq1rqHDh3yOnXq5K5N+JDQGipWQ3jrtcqp4V0/+uijiJ9jDU2r90H3nd53DXXbsmXLWMMGRzofDeWtst10001uaNj4hpuN9Ps90u8tDWmsc9H7p/e5e/fu7nOq9cKHHRcdU0NLI33KoH9SO7gBkDb5X9CmJ5PJ8bQQOJ/oibmeQqulLlJaGnA+U2uIWl30ZYNqIRKNcqY0UQ1NTYtF+kQfCwAAzgLl0isNSmlX0XaYBs5FcftrKGhWGqZS1MK/XV7pckovJKhIv+hjAQDAWXLTTTe5CTifqY+PgguNWKb+NuojomGGNZR3+MhzY8eOTdVyIvURWAAAACBeGgRDHe0/+ugjN6S0OvarxSKxQQyQ/tDHAgAAAEBg9LEAAAAAEBiBBQAAAIDA6GOBQPRlPb///rv79ti4X5IDAACA85t6TeiLLvWFpPoyy4QQWCAQBRWlSpVK7WIAAADgLNq+fbtdcMEFCa5DYIFA1FLh32wazxoAAABpx8GDB91DZL/OlxACCwTipz8pqCCwAAAASJuiSXmn8zYAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBZQ6+C8Bs4orZlj0mZ2oXAwAAIM3qX7e9nctosQAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWITJkCGDzZo1y9KrrVu3umuwZs2a1C4KAAAAzjMEFmF27NhhLVu2tHPF4sWLXUV///79KbIdAAAAcKYyn/GWacyxY8esWLFiqV0MAAAA4LyUblssmjRpYv369bOBAwdaoUKFrEWLFqelQm3fvt06dOhg+fLlswIFCljbtm1dupDvxIkT1r9/f7e8YMGCNmzYMOvWrZu1a9cutM7Ro0fdOkWKFLHs2bNbw4YNbcWKFYmWT8dp2rSp+zl//vyubN27d090nwltN3fuXLeuX97WrVvbpk2bku2aAgAAIP1Kt4GFTJkyxbJmzWrLli2ziRMnxlp2/PhxF2zkzp3blixZ4tbJlSuXXXvtta51Q8aNG2fTpk2zSZMmueUHDx48rY/G3Xffbe+//7471qpVq6x8+fJuv3v37k2wbKVKlXLbyYYNG1ya1tNPP53oPhPa7u+//7bBgwfbt99+a5999pllzJjR2rdvb6dOnYr6mimo0XmGTwAAAEC6ToWqUKGCPfrooxGXvf32267C/corr7in/qIAQk/71YehefPmNmHCBBs+fLirnMuzzz5rH3/8cWgfqsi/8MILNnny5FDfjZdfftk+/fRTe/XVV23o0KHxli1TpkyulUTUMqHjRrvPSNvJ9ddfH+sYr732mhUuXNh+/PFHu/TSS6O6ZmPGjLGRI0dGtS4AAADSj3TdYlGrVq14l61du9Y2btzoWizUUqFJFfYjR4649KEDBw7Yzp077fLLL48VDITvU+up5aNBgwaheVmyZHHbrF+//ozKHGSfv/zyi3Xs2NHKli1refLksTJlyrj527Zti/r4CqR07v6kdDEAAAAgXbdYxMTExLvs0KFDLkhQqlNcesp/PmrTpo2VLl3atXCUKFHCtciopcJP7YpGtmzZ3AQAAACES9ctFgmpWbOme8KvdCL1YQif8ubN66aiRYvG6oh98uRJ1+fBV65cuVAfDp9aG7RNlSpVEi2DtvX3m5R9Rtpuz549rs/FiBEjrFmzZla5cmXbt29fgCsEAAAA/H8EFvHo3LmzGy1KI0Gp8/aWLVtc3wqNxvTbb7+5de68807X5+CDDz5wlfYBAwa4yrrfJ0MtIn369HH9HjQik/oy9OzZ0w4fPmw9evRItAxqXdC+PvroI/vzzz9dK0o0+4y0nUaI0khQL730kkvxWrhwoevIDQAAACQHAot45MyZ07744gu78MIL7brrrnNP+FVxVx8L9U8QDS+rPgtdu3a1evXquX4YGp1JQ8D6xo4d6zpNd+nSxbWCqFI/b948V9FPTMmSJV1H6Xvuuce1jmh43Gj2GWk7jQA1ffp0W7lypUt/GjRokD322GNn7foBAAAgfcngeZ6X2oVIK9RnQQGIvvvioYcesvRAw80qLWzcgjcse0zO1C4OAABAmtW/7v+ORJoadT0N2uM/XI9Puu68HdSvv/5q8+fPt8aNG7vvd9Bws0qZ6tSpU2oXDQAAAEhRpEIFoPQifZ9EnTp13PCv69atswULFrhWi2j07t07NJRt3EnLAAAAgPMFLRYB6Fuuw0dnSqpRo0bZkCFDIi5LrKkJAAAAOJcQWKQiDWWrCQAAADjfkQoFAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAATGF+QhWfSu04ZvCwcAAEjHaLEAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAALjC/KQLCaumG3ZY3Km2PH6122fYscCAABA4mixAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAos0bPLkyZYvX77Q6wcffNAuu+yyVC0TAAAA0qY0E1g0adLEBg4cmNrFOKcNGTLEPvvss9QuBgAAANKgzKldAKScXLlyuQkAAABIbmmixaJ79+72+eef29NPP20ZMmRw09atW+3777+3li1busp00aJFrUuXLrZ79+5YrRx33nmna+nInz+/W+fll1+2v//+22655RbLnTu3lS9f3j755JPQNosXL3b7nzNnjlWrVs2yZ89udevWdcdKSnrSRx99ZJUqVbKcOXPaDTfcYIcPH7YpU6ZYmTJlXFn69+9vJ0+eDG139OhR1+JQsmRJi4mJsSuuuMKVJe6+L7zwQrfP9u3b2549e2Itj5sKtWLFCrvmmmusUKFCljdvXmvcuLGtWrXqjN4DAAAApG9pIrBQQFGvXj3r2bOn7dixw00KCq666iqrUaOGffvttzZ37lzbuXOndejQIda2qsyrYv3NN9+4IKNPnz524403Wv369V0lu3nz5i4gUcU/3NChQ238+PGucl64cGFr06aNHT9+PKryal/PPPOMTZ8+3ZVLAYICgY8//thNU6dOtRdffNHee++90Db9+vWz5cuXu22+++47V8Zrr73WfvnlF7f866+/th49erj11qxZY02bNrWHH344wXL89ddf1q1bN1u6dKl99dVXVqFCBWvVqpWbDwAAACRFBs/zPEsD1Pqgp/FPPfWUe61K9ZIlS2zevHmhdX777TcrVaqUbdiwwSpWrOi2UauA1hP9rCf31113nb3++utu3h9//GHFixd3lXq1TCgIUKVdFfybbrrJrbN371674IILXItB3MAlLq2j1pCNGzdauXLl3LzevXu7YEKBj5+qpKBBrRcTJ060bdu2WdmyZd3/JUqUCO3r6quvtssvv9xGjx5tnTp1sgMHDriWFN/NN9/sApf9+/eHWixmzZrlAo9ITp065VpT3nzzTWvdunXEddRyosl38OBBd03HLXjDssfktJTSv277FDsWAABAenXw4EFXP1Y9M0+ePGm/xSKStWvX2qJFi0L9CjRdfPHFbtmmTZtC6ymdyZcpUyYrWLCgVa1aNTRP6VGya9euWPtXC4mvQIECLq1p/fr1UZVNqUp+UOEfQ0FEeP8HzfOPuW7dOhf0KBgKPx+lf/nnomMrPSq+MkaiQEatPGqp0A2jm+XQoUMugInPmDFj3Lr+pKACAAAASLOdt1VBVnrSuHHjTlumFghflixZYi1T/4nweXrtP81PLokd05/nH1PnoqBn5cqV7v9wQTpjKw1K/TCUSla6dGnLli2bC0aOHTsW7zbDhw+3wYMHn9ZiAQAAgPQtzQQWWbNmjdXZuWbNmvb++++7loDMmZP/NNUnQR2lZd++ffbzzz9b5cqV7WxQPxGdm1owGjVqFHEdHVv9LOKWMSHLli2z559/3vWrkO3bt8fq3B6Jgg9NAAAAQJpMhVIAoYq1RoNS5bhv376u70PHjh1dB2ulDKm/hfo3hAcgZ2rUqFHuOyE0GpRGpVIH8Hbt2tnZoBSozp07W9euXW3GjBm2ZcsW19lcaUl+nwqNIqX+FI8//rjr0P3ss8+61wlRCpT6diiNStdOx8iRI8dZOQcAAACkbWkmsNBQrEoTqlKlihulSek8eiKvIEIjO6nfhIaVVefkjBmDn/bYsWNtwIABVqtWLdfBe/bs2a7V5GyZNGmSCyzuuusu159DQYwCJr/VRB3LNVSu0pqqV69u8+fPtxEjRiS4z1dffdW1tqh1RyNfKTgpUqTIWTsHAAAApF1pZlSolOKPCqUKuYKU9M4fKYBRoQAAANIeRoUCAAAAkKIILJKZ/03fkSZ93wQAAACQFqWZUaFSir5UL6HssVdeecX++eefiMv0fRcAAABAWkRgkcxKliyZ2kUAAAAAUhypUAAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYHxBHpJF7zptLE+ePKldDAAAAKQSWiwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAExjdvI1lMXDHbssfkTNI2/eu2P2vlAQAAQMqixQIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAczuw8DzPevXqZQUKFLAMGTLYmjVrknX/2uesWbPcz1u3bo11jMWLF7vX+/fvT9ZjpnUPPvigXXbZZaldDAAAAJxnzmpgMXfuXJs8ebJ99NFHtmPHDrv00kuTtbKrfbZs2TLiNvXr13fL8+bNaymle/fu1q5du3Nin2ejLAAAAEB8MttZtGnTJitevLir5J9pi8fJkyfjXV6sWLF4l2XNmjXB5QAAAADOgxYLPTG/8847bdu2bS4lqUyZMnbq1CkbM2aMXXTRRZYjRw6rXr26vffee6Ft/PSlTz75xGrVqmXZsmWzN954w0aOHGlr1651yzSpFSRuKlRccVOhmjRpEto+fFIKlTzxxBNWtWpVi4mJsVKlStkdd9xhhw4dCu1Px8yXL5/NmzfPKleubLly5bJrr73WtYr4rSpTpkyxDz74ILRvlUG2b99uHTp0cNsrLaxt27ah4yYkoX2uW7fOrrrqKncdCxYs6FLO/PImtN2wYcOsYsWKljNnTitbtqzdd999dvz48TN8lwEAAICz3GLx9NNPW7ly5eyll16yFStWWKZMmVxQoUBh4sSJVqFCBfviiy/sP//5jxUuXNgaN24c2vaee+6xxx9/3FV8s2fPbnfddZdLq1qwYIFbfibpTTNmzLBjx46FXvft29d++OEHK1q0qHudMWNGe+aZZ1zQs3nzZhdY3H333fb888+Htjl8+LAr19SpU936KvuQIUNs2rRp7v/169fbwYMHbdKkSW59BRGqtLdo0cLq1atnS5YsscyZM9vDDz/sgpLvvvvOtazEJ759/v3336F96tru2rXLbrvtNuvXr58LgOLbTnLnzu3WKVGihAtOevbs6ebpXAEAAIBzLrBQ5V8VVgUUSkk6evSojR492gUHqhCLAoelS5faiy++GCuwGDVqlF1zzTWh12odUIU8SGqTX7GWJ5980hYuXGhff/21e+IvAwcODC1X64oq/717944VWChIUFCkgElUkVdZ/TJqXzrP8HIqkFJLzSuvvOJaDkSVfbVeqBWhefPm8ZY5vn2qNeLIkSP2+uuvuxYWefbZZ61NmzY2btw4FyxF2k5GjBgR6zwVhEyfPj3qwEL71ORT8AIAAACc1T4W4TZu3Oie+IcHDKJWhBo1asSaV7t27bNWDqVZqUVk9uzZLiXIp4BHLSo//fSTqyyfOHHCVd5VZqUNif73gwpR/xG1FiREKVw6dwVZ4bRv9UE5E2qNUBqZH1RIgwYNXACzYcOGUCtMJG+//bZrmdGxlTql88yTJ0/Ux9Y1UmoaAAAAkCqBhZ//P2fOHCtZsmSsZepLES68wpycfvzxR7v55ptt7NixsVoK1N+hdevW1qdPH3vkkUdc64ZaUnr06OECHz+wyJIlS6z9qQVCHcwTO2/1F1G6VFxKAUtJy5cvt86dO7vAQKlUalVSa8X48eOj3sfw4cNt8ODBodcKwtQnBQAAAOlbigUWVapUcQGEOnOHpz1FQ/0QEhodKhq7d+92qULXX3+9DRo0KNaylStXuqf9qmCr74S88847ST5GpHLWrFnTtRIUKVIkSS0DCe1TncfVT0J9LfwgbNmyZa7slSpVine7L7/80kqXLm333ntvaN6vv/6apPLoPYwbCAIAAAAp9s3bSgVSPr8q9eojoFScVatW2YQJE9zrhKgvwJYtW9yX3ylACM/xj5YCCrU8aMSkP/74IzSp8l2+fHnXf0JlUcdtdc5WX4qkUjnVIVvpSCqn9qkWgkKFCrmRoNR5W+ehvhX9+/e333777Yz3qU7t3bp1s++//94WLVrkRuDq0qVLKA0q0nbqMK/ATq0Uuv5KiZo5c2aSzxMAAABItcBCHnroITe8qfL09dRdIyMpNUojMSUWFGjdpk2buvSht956K8nH1ghUqoTrib36RviThoJVfwUNN6uOz/oSP6UtqYxJpRGW1GKgPiIqp1oRFMzo2BdeeKFdd9117ryVYqU+FtG0YMS3Tw17u3fvXqtTp47dcMMN1qxZM9eBO6Ht/v3vf7vATp3O9YWDasHQ+wEAAAAElcFLrJMAkAD1sVBfjXEL3rDsMf/bFyVa/eu2P2vlAgAAQPLV9Q4cOJDoQ/EUbbEAAAAAkDYRWKQyfVdFfJP6ZAAAAADngxQbFQqRqUN6fOIOywsAAACcqwgsUplGpAIAAADOd6RCAQAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACB8QV5SBa967SxPHnypHYxAAAAkEposQAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAY37yNZDFxxWzLHpMz0fX6122fIuUBAABAyqLFAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwQS5MmTWzgwIGpXQwAAACcZwgs0kFFe/HixZYhQwbbv39/ahcFAAAAaRSBBQAAAIDACCwS0L17d/v888/t6aefdk/8NW3dutW+//57a9mypeXKlcuKFi1qXbp0sd27d8dq5bjzzjtdS0f+/PndOi+//LL9/fffdsstt1ju3LmtfPny9sknn5zWqjBnzhyrVq2aZc+e3erWreuOFY1ff/3V2rRp444XExNjl1xyiX388ceuvE2bNnXraJmOofMSladr167uPIoXL27jx49P9msIAACA9IHAIgEKKOrVq2c9e/a0HTt2uElBwVVXXWU1atSwb7/91ubOnWs7d+60Dh06xNp2ypQpVqhQIfvmm29ckNGnTx+78cYbrX79+rZq1Spr3ry5C0gOHz4ca7uhQ4e6Cv6KFSuscOHCLlg4fvx4omXt27evHT161L744gtbt26djRs3zgUMpUqVsvfff9+ts2HDBncOOi//WAqcPvjgA5s/f74LblS2hOgYBw8ejDUBAAAABBYJyJs3r2XNmtVy5sxpxYoVc9MLL7zggorRo0fbxRdf7H5+7bXXbNGiRfbzzz+Htq1evbqNGDHCKlSoYMOHD3ctEAo0FKRo3v3332979uyx7777LtYxH3jgAbvmmmusatWqLjhR0DJz5sxEy7pt2zZr0KCB265s2bLWunVru/LKKy1TpkxWoEABt06RIkXcOei8Dh06ZK+++qo9/vjj1qxZs9DxTpw4keBxxowZ47b3JwUuAAAAAIFFEq1du9YFEWoN8CcFGLJp06bQekpn8qlyX7BgQVd59yk9Snbt2hVr/2oh8SkgqFSpkq1fvz7RcvXv398efvhhF1woOIkbsMSlsh47dsyuuOKK046XEAVJBw4cCE3bt29PtGwAAABI+wgskkhP+pWetGbNmljTL7/84loIfFmyZIm1nfo2hM/Tazl16lSylOu2226zzZs3u/QqpULVrl3bJkyYYMktW7ZslidPnlgTAAAAQGCRCKVCnTx5MvS6Zs2a9sMPP1iZMmVcB+zwSZ2mg/rqq69CP+/bt8+lV1WuXDmqbZWW1Lt3b5sxY4bdddddrsO4fw4Sfh7lypVzgc7XX3992vEAAACApCKwSIQCCFW+NbqSRn5SJ+m9e/dax44dXQdrpRTNmzfPjfYUXnE/U6NGjbLPPvvMjQal0ZvUL6Ndu3aJbqcRqFSOLVu2uA7YStfyA5LSpUu7FpKPPvrI/vzzT9fqohSuHj16uA7cCxcuDB0vY0ZuCQAAACQdtchEDBkyxPWRqFKlihulSf0Sli1b5oIIjeykfhOq1OfLly9ZKuVjx461AQMGWK1ateyPP/6w2bNnh1ocEqLyKOhRMHHttddaxYoV7fnnn3fLSpYsaSNHjrR77rnH9e3o16+fm//YY49Zo0aNXGrX1VdfbQ0bNnTHBQAAAJIqg+d5XpK3QrLTUK/6vgmlIylIOV9ouFmNDjVuwRuWPSZnouv3r9s+RcoFAACA5KvradCexPrW0mIBAAAAIDACi/OE/03fkSZ9pwYAAACQmjKn6tER0qRJE0soK+2VV16xf/75J+Iy/wvwAAAAgNRCYHGeUAdsAAAA4FxFKhQAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBhfkIdk0btOG8uTJ09qFwMAAACphBYLAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwviAPyWLiitmWPSan+7l/3fapXRwAAACkMFosAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYOkusGjSpIkNHDjQ/VymTBl76qmnknX/GTJksFmzZtn5aPLkyZYvX77ULgYAAADOQ+kusDjbduzYYS1btkyWfT344IN22WWXpdh2AAAAwJnKfMZbIqJixYqldhEAAACAFEeLxf/ZunWrS2Nas2ZNaN7+/fvdvMWLF9upU6fsggsusBdeeCHWdqtXr7aMGTPar7/+GjEVatiwYVaxYkXLmTOnlS1b1u677z47fvx4VGlJI0eOtLVr17p9atI82bZtm7Vt29Zy5cplefLksQ4dOtjOnTsT3e6JJ56wqlWrWkxMjJUqVcruuOMOO3ToUDJdQQAAAKRntFhEScFDx44d7c0337Q+ffqE5k+bNs0aNGhgpUuXjrhd7ty5XcW+RIkStm7dOuvZs6ebd/fddyd4vJtuusm+//57mzt3ri1YsMDNy5s3rwtw/KDi888/txMnTljfvn3d+gqA4tvOP4dnnnnGLrroItu8ebMLLFSO559/PurrcPToUTf5Dh48GPW2AAAASLsILJKgc+fONn78eNdicOGFF7pK/vTp023EiBHxbhO+TJ3FhwwZ4rZJLLDIkSOHCx4yZ84cK73q008/dQHKli1bXKuDvP7663bJJZfYihUrrE6dOhG3E7/Tul+Whx9+2Hr37p2kwGLMmDGuRQQAAAAIRypUEqhDdOXKlV2rhajFYNeuXXbjjTfGu83bb7/tWjRUyVeFX4GGApMztX79ehdQ+EGFVKlSxY3mpGUJUQtGs2bNrGTJkq7VpEuXLrZnzx47fPhw1McfPny4HThwIDRt3779jM8FAAAAaQeBxf9RmpB4nheaF6kvhFot/MBC/1977bVWsGDBiPtcvny5W79Vq1b20Ucfuf4Y9957rx07dsxSow9J69atrVq1avb+++/bypUr7bnnnnPLklKebNmyuX4d4RMAAABAYPF/ChcuHBou1hfekdvXqVMn14dBFfP33nvPBQ7x+fLLL13fCwUTtWvXtgoVKoQ6eUcja9asdvLkyVjz1GKiVoLwloIff/zRdTRXy0V826m8St1SKlfdunVdh/Lff/896rIAAAAACaGPRVifBlW4x44d6zo3K8UpUt8J9U2oX7++9ejRw1Xe//3vf8e7TwUSSntSnwr1fZgzZ47NnDkz6jLpWOpLoQBHI1Ipfenqq692IzspoNGX+6nztjphN27c2AUv8W1Xvnx51wIzYcIEa9OmjS1btswmTpx4hlcLAAAAiI0WizCvvfaaq6jXqlXLdXRW5+ZIVKnXcK7t27d3AUl8FHQMGjTI+vXr5/pnqAVDw81G6/rrr3epVk2bNnUtKm+99ZYbPvaDDz6w/Pnz25VXXukCDQ1jq74cCW1XvXp1N9zsuHHj7NJLL3WjWakjNgAAAJAcMnjhnQqAJNJwsxrOdtyCNyx7TE43r3/d9qldLAAAACRjXU+D9iTWt5YWCwAAAACBEVikIn33hIagjTQpVQkAAAA4X9B5OxV9/PHHEYe0laJFi6Z4eQAAAIAzRWCRijQULQAAAJAWkAoFAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAATGF+QhWfSu08by5MmT2sUAAABAKqHFAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACyWLiitmpXQQAAACkIgILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAACQsoGF53nWq1cvK1CggGXIkMHWrFljyUn7nDVrlvt569atsY6xePFi93r//v3Jesy0rHv37tauXbvQ6yZNmtjAgQNTtUwAAABImzInZeW5c+fa5MmTXSW/bNmyVqhQoTM66IMPPugCiLiByY4dOyx//vwRt6lfv75bnjdvXkvJirkCGT/YOd/NmDHDsmTJktrFAAAAQHoPLDZt2mTFixd3lfwzoRaPkydPxru8WLFi8S7LmjVrgsuROLU0AQAAAKmaCqWn93feeadt27bNpSSVKVPGTp06ZWPGjLGLLrrIcuTIYdWrV7f33nsvtI2fvvTJJ59YrVq1LFu2bPbGG2/YyJEjbe3atW6ZJrWCxE2FiituKpTSevztwyelUMkTTzxhVatWtZiYGCtVqpTdcccddujQodD+dMx8+fLZvHnzrHLlypYrVy679tprXauI36oyZcoU++CDD0L7Vhlk+/bt1qFDB7e9Kutt27YNHTfa9KTRo0db0aJF3T5GjRplJ06csKFDh7r9XXDBBTZp0qRY2yV2TAVsgwcPdssLFixod999twvkwsVNhdq3b5917drVtRLlzJnTWrZsab/88ktU5wEAAACcUWDx9NNPuwqwKr2qfK9YscIFFa+//rpNnDjRfvjhBxs0aJD95z//sc8//zzWtvfcc4+NHTvW1q9fb9dcc43ddddddskll7j9aLrpppvsTNJ6/O01XXfddVapUiVXWXcnljGjPfPMM65cChAWLlzoKtvhDh8+bI8//rhNnTrVvvjiCxc0DRkyxC3T/6rI+8GGJrXUHD9+3Fq0aGG5c+e2JUuW2LJly0JBybFjx6Iqu8ry+++/u2MqAHrggQesdevWroL/9ddfW+/eve3222+33377za0fzTHHjx/vgqXXXnvNli5danv37rWZM2cmGuR8++239uGHH9ry5ctdINKqVSt3vPgcPXrUDh48GGsCAAAAVJmM2pNPPumVLl3a/XzkyBEvZ86c3pdffhlrnR49engdO3Z0Py9atEiPzL1Zs2bFWueBBx7wqlevftr+te7MmTPdz1u2bHGvV69eHWtf+/btO227J554wsuXL5+3YcOGeMv+7rvvegULFgy9njRpktvfxo0bQ/Oee+45r2jRoqHX3bp189q2bRtrP1OnTvUqVarknTp1KjTv6NGjXo4cObx58+bFe/zwfeoanjx5MjRP+2vUqFHo9YkTJ7yYmBjvrbfeivqYxYsX9x599NHQ8uPHj3sXXHBBrPI3btzYGzBggPv5559/due/bNmy0PLdu3e7fb7zzjvxll/vnbaLO41b8Eai5w4AAIDzy4EDB1xdT/8nJkl9LMJt3LjRPfFXC0Q4PUGvUaNGrHm1a9e2s0VpVmoRmT17tlWsWDE0f8GCBa5F5aeffnJP1ZVqdOTIEVdmpf2I/i9XrlxoG/Uf2bVrV4LHUwqXzl2tB+G0b/VBiYZaa9Si4lMry6WXXhp6nSlTJpfO5JclsWMeOHDAtahcccUVoWWZM2d21z1uOpRPrUdaJ3wbHVOtPloWn+HDh7uUK5+urVLNAAAAkL6dcWDh91eYM2eOlSxZMtYy9aUIp34OZ8OPP/5oN998s0uzat68eWi++h4otahPnz72yCOPuD4JSg/q0aOHC3z8wCLuCEnqRxFfRTz8vNVfZNq0aactK1y4cFTljnTcSPPUhyW5jplc9N7GfX8BAACAMw4sqlSp4iqY6pfQuHHjJG2rEZ4SGh0qGrt377Y2bdrY9ddf7/p2hFu5cqWrlKvfgd8y8M477yT5GJHKWbNmTXv77betSJEilidPHksJ0RxTrS3qn3HllVe612qh0XXQtpGow7rW0Tb+KF979uyxDRs2uPcWAAAASJFv3lZajjo4q1KvztFKyVm1apVNmDDBvU6IRpTasmWL+x4LBQjqEJxUCijU8qDRm/7444/QpECgfPnyrgOyyrJ582bXOVsdzJNK5fzuu+9cZVvl1D47d+7svr9DozKpI7XOQ6NF9e/fP9TZOrlFc8wBAwa4lhuNqqX0L42CldCXCVaoUMHtr2fPnq41R+lW6niv1ifNBwAAAFIksJCHHnrI7rvvPteXQU/ANUqRUqM0/GxiQYHWbdq0qUvleeutt5J8bI2o9P3331vp0qXd03p/0rCsGvZWoy2NGzfO9V1QCpHKmFSqdKvPgfoqqJwajUnBjI594YUXupGodN5KsVJ/h7PVghHNMTXSVpcuXaxbt25Wr149F/i1b98+wf1qSFulWCltTNsoDezjjz/mS/QAAACQZBnUgzvpmwH/v/O2vg193II37O5mnVO7OAAAADgLdT0NFpTYQ/RALRYAAAAAIAQWyUxfXBffpP4RAAAAQFp0xqNCITJ1SI9P3GF5AQAAgLSCwCKZaUQqAAAAIL0hFQoAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAsmid502qV0EAAAApCICCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILJIuJK2andhEAAACQiggsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAgszQcWGTJksFmzZll6tHjxYnf++/fvd68nT55s+fLlS+1iAQAAIA3KbGncjh07LH/+/KldjHPCTTfdZK1atUrtYgAAACANStOBxbFjx6xYsWKpXYxzRo4cOdwEAAAAJLc0lQrVpEkT69evnw0cONAKFSpkLVq0OC0Vavv27dahQweXElSgQAFr27atbd26NbT8xIkT1r9/f7e8YMGCNmzYMOvWrZu1a9cutM7Ro0fdOkWKFLHs2bNbw4YNbcWKFUlKT5o3b57VqFHDVfSvuuoq27Vrl33yySdWuXJly5Mnj3Xq1MkOHz4c2u7UqVM2ZswYu+iii9w21atXt/feey/Wvj/++GOrWLGiW960adNY5xVfKtQLL7xg5cqVs6xZs1qlSpVs6tSpSbjiAAAAQBoMLGTKlCmukrxs2TKbOHFirGXHjx93wUbu3LltyZIlbp1cuXLZtdde61o3ZNy4cTZt2jSbNGmSW37w4MHT+mjcfffd9v7777tjrVq1ysqXL+/2u3fv3qjL+eCDD9qzzz5rX375ZSjYeeqpp+zNN9+0OXPm2Pz5823ChAmh9RVUvP766+6cfvjhBxs0aJD95z//sc8//9wt1z6uu+46a9Omja1Zs8Zuu+02u+eeexIsw8yZM23AgAF211132ffff2+333673XLLLbZo0aKozwMAAABwvDSkcePGXo0aNWLN0ynOnDnT/Tx16lSvUqVK3qlTp0LLjx496uXIkcObN2+ee120aFHvscceCy0/ceKEd+GFF3pt27Z1rw8dOuRlyZLFmzZtWmidY8eOeSVKlPAeffTRRMu4aNEiV6YFCxaE5o0ZM8bN27RpU2je7bff7rVo0cL9fOTIES9nzpzel19+GWtfPXr08Dp27Oh+Hj58uFelSpVYy4cNG+b2u2/fPvd60qRJXt68eUPL69ev7/Xs2TPWNjfeeKPXqlWreMuvshw4cCA0bd++3R1j3II3Ej13AAAAnF9U31NdT/8nJs21WNSqVSveZWvXrrWNGze6Fgu1VGhSOtSRI0ds06ZNduDAAdu5c6ddfvnloW0yZcoUa59aTy0fDRo0CM3LkiWL22b9+vVRl7NatWqhn4sWLWo5c+a0smXLxpqn9ChRmZUWdc0114TKrUktGCqP6NhXXHFFrGPUq1cvwTJom/DzEL1O6DzUcpI3b97QVKpUqajPGQAAAGlXmuu8HRMTE++yQ4cOuSBBqU5xFS5c2FKSghGf+lyEv/bnqV+FX25RilTJkiVjrZctWzZLScOHD7fBgweHXitVjOACAAAAaa7FIiE1a9a0X375xXW6Vr+I8Ml/Aq+WgvCO2CdPnnT9KHx+R2f1v/CpBUPbVKlS5ayUW/tVALFt27bTyu1X6tXp+5tvvom13VdffZXgfrVN+HmIXid0HiqHOpeHTwAAAECaa7FISOfOne2xxx5zI0GNGjXKLrjgAvv1119txowZrkO2Xt95550u3UeV9osvvth1oN63b59rQfBbRPr06WNDhw51aVQXXnihPfrooy5VqUePHmel3ErdGjJkiOuwrVYMjUKltC0FAarYa9Sq3r172/jx41251HF75cqVbhSohGhddRrX6FRXX321zZ49212LBQsWnJXzAAAAQNqVrgIL9WP44osv3BCyGkHpr7/+cqlFzZo1Cz1517I//vjDunbt6vpX9OrVy434pJ99Y8eOdRX8Ll26uH3Url3bDR97Nr+I76GHHnLpWgp6Nm/e7IaNVQvM//zP/7jlCnA0UpWCDwVD6vMxevRou/XWW+Pdp4bQffrpp+3xxx93o0NpKFuNhqVhewEAAICkyKAe3EnaIp1RAKGUIT3ZV+UesamPhVLIxi14w+5u1jm1iwMAAICzUNdTtkxiKfDpqsUiGkqN0ndING7c2H0Rnr5rYsuWLe4L6wAAAABElq46b0cjY8aMrm9CnTp13NCr69atc30O1GoRDfV1CB8SNnzSMgAAACAtosUiDo2yFHekpKRQp3B1tI6EEZQAAACQVhFYJDMNZasJAAAASE9IhQIAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwQLLoXadNahcBAAAAqYjAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFkgWE1fMTu0iAAAAIBURWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAAAQWJoPLLZu3WoZMmSwNWvWBNpPkyZNbODAgYH2sXjxYleW/fv3B9rP+Xp8AAAApF2ZLY0rVaqU7dixwwoVKpTaRQEAAADSrDQdWBw7dsyyZs1qxYoVS+2iAAAAAGnaOZMK9dJLL1mJEiXs1KlTsea3bdvWbr31Vtu0aZP7uWjRopYrVy6rU6eOLViwINa6ZcqUsYceesi6du1qefLksV69ekVMhfr++++tZcuWbj/aX5cuXWz37t2h5X///bfbh5YXL17cxo8ff1p5p06darVr17bcuXO7wKVTp062a9euWOt8/PHHVrFiRcuRI4c1bdrUlSUpli1b5lKwcubMafnz57cWLVrYvn373LKjR49a//79rUiRIpY9e3Zr2LChrVixIsnHX7p0qTVq1Mito9Yd7VPnDwAAAJyXgcWNN95oe/bssUWLFoXm7d271+bOnWudO3e2Q4cOWatWreyzzz6z1atX27XXXmtt2rSxbdu2xdrP448/btWrV3fr3HfffacdR/0LrrrqKqtRo4Z9++23bv87d+60Dh06hNYZOnSoff755/bBBx/Y/PnzXd+EVatWxdrP8ePHXRCzdu1amzVrlqu0d+/ePbR8+/btdt1117kyKqi57bbb7J577on6emibZs2aWZUqVWz58uUuANC+Tp486Zbffffd9v7779uUKVNc2cqXL+8CD12zaI+vYE3X8frrr7fvvvvO3n77bXecfv36RV1OAAAAwPHOIW3btvVuvfXW0OsXX3zRK1GihHfy5MmI619yySXehAkTQq9Lly7ttWvXLtY6W7Zs8XSaq1evdq8feughr3nz5rHW2b59u1tnw4YN3l9//eVlzZrVe+edd0LL9+zZ4+XIkcMbMGBAvGVfsWKF24e2l+HDh3tVqlSJtc6wYcPcOvv27Uv0WnTs2NFr0KBBxGWHDh3ysmTJ4k2bNi0079ixY+5aPfroo1Efv0ePHl6vXr1irbNkyRIvY8aM3j///BPx2EeOHPEOHDgQmvxrN27BG4meEwAAAM4vqu+prqf/E3POtFiIWib0FF5pPjJt2jS7+eabLWPGjK7FYsiQIVa5cmXLly+fS1Nav379aS0WSk9KiFoY1Cqi7f3p4osvDj3B16S+GVdccUVomwIFClilSpVi7WflypWuNeDCCy906VCNGzd28/3yqGzh+5B69eolucUiEpVRLSYNGjQIzcuSJYtdfvnl7rjRHl/XYvLkybGuhVo9lI62ZcuWiMceM2aM5c2bNzQpfQoAAAA4pzpvq6LueZ7NmTPH9aFYsmSJPfnkk26ZgopPP/3UpTop7Ud9Am644QYXBISLiYlJ8BgKUHSccePGnbZM/Sk2btyYaDnVB0EVcE0KfgoXLuwCCr2OW54zpfM723Qtbr/9dtevIi4FTJEMHz7cBg8eHHp98OBBggsAAACcW4GFOiGrX4Aq66rgq5WgZs2aoY7M6sPQvn37UKU4qZ2hRftTq4g6emfOfPrplytXzj39//rrr0OVa3WY/vnnn0OtEj/99JPrDzJ27NhQpVr9NcKpZeXDDz+MNe+rr76KupzVqlVz/UlGjhwZsYwa7UrXpHTp0m6eWjDUedv/ro1ojq9r8eOPP7pALVrZsmVzEwAAABDunEqF8tOh1GLx2muvuZ99FSpUsBkzZrgUIaXwaBSmuCNIRaNv376ug3PHjh1dRVxpRfPmzbNbbrnFdYxWOlCPHj1cB+6FCxe6EaQU0Cgdy6eAQxX7CRMm2ObNm10FXh25w/Xu3dt++eUXt58NGzbYm2++6dKOoqWWAZXvjjvucB2rFcy88MILbvQqtcr06dPH7VudzxUc9OzZ0w4fPuzKHu3xhw0bZl9++aXrrK3rqvXVYZ3O2wAAADjvAwuN2KQ+DaoMK3jwPfHEE27I1fr167tUJqUd+a0ZSaEhbfWkX0FE8+bNrWrVqu4pv/pt+MHDY4895oZg1XGuvvpqN5RrrVq1QvtQ6pMq6e+++64btUktF0rRCqfgQy0jGjFKo1RNnDjRRo8eHXU5NUysRqRSEKW+E+ofoUq/38qiY2o0Jw2Vq+ugFh4FSLpG0R5frSIa/UqtMTpfjZR1//33u2sEAAAAJEUG9eBO0hZAGPWxUCfucQvesLub/f8WJgAAAKSdut6BAwfc98SdVy0WAAAAAM4/BBapxP/m70hTUlKmAAAAgHPBOTUqVHryyiuv2D///BNxmfqYAAAAAOcTAotUUrJkydQuAgAAAJBsSIUCAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsECy6F2nTWoXAQAAAKmIwAIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAotzSIYMGWzWrFnJsq8HH3zQLrvssmTZFwAAAHDOBBZNmjSxgQMHptThAAAAAKQgWiySwbFjx1K7CAAAAEDaDyy6d+9un3/+uT399NMu3UfTpk2brEePHnbRRRdZjhw5rFKlSm553O3atWtno0ePtqJFi1q+fPls1KhRduLECRs6dKgVKFDALrjgAps0aVJU5di6das79vTp061+/fqWPXt2u/TSS13ZfCdPnoy6XI888oiVKFHCrSO//fabdezY0ZUrJibGateubV9//XVouw8++MBq1qzpjlu2bFkbOXKkO5f4DBs2zCpWrGg5c+Z069933312/PhxS4qpU6damTJlLG/evHbzzTfbX3/9FVo2d+5ca9iwobuuBQsWtNatW7v3BQAAAEiqzJYCVDH/+eefXSVegYHkz5/fBQXvvvuuq9R++eWX1qtXLytevLh16NAhtO3ChQvdel988YUtW7bMVfq17pVXXukq7W+//bbdfvvtds0117j1oqGg5KmnnrIqVarYE088YW3atLEtW7a4cpw6dSqqcn322WeWJ08e+/TTT93rQ4cOWePGja1kyZL24YcfWrFixWzVqlVuf7JkyRLr2rWrPfPMM9aoUSNXgdd+5YEHHohYzty5c9vkyZNd8LJu3Trr2bOnm3f33XdHdZ46hvpsfPTRR7Zv3z5X/rFjx7qASP7++28bPHiwVatWzZX//vvvt/bt29uaNWssY8bIMefRo0fd5Dt48GBUZQEAAEAa56WQxo0bewMGDEhwnb59+3rXX3996HW3bt280qVLeydPngzNq1SpkteoUaPQ6xMnTngxMTHeW2+9lWgZtmzZ4umUx44dG5p3/Phx74ILLvDGjRuXpHIVLVrUO3r0aGjeiy++6OXOndvbs2dPxH00a9bMGz16dKx5U6dO9YoXLx56rbLNnDkz3nI89thjXq1atbxoPPDAA17OnDm9gwcPhuYNHTrUu+KKK+Ld5s8//3RlWLduXYL71TpxpwMHDkRVLgAAAJw/VMeLtq6XIi0W8Xnuuefstddes23bttk///zj+irEHcnokksuifX0XClRavnwZcqUybUs7Nq1K+rj1qtXL/Rz5syZXcrS+vXrk1SuqlWrWtasWUOv9ZS/Ro0aLg0qkrVr17oWF7+1wE+7OnLkiB0+fNilO8Wl1hi1cKjlQS0KSptSK0m0lAKlFg6fWl3Cr9Mvv/ziWinU8rN79+5Q64rOO/wahxs+fLhr5QhvsShVqlTUZQIAAEDalGqBhfo5DBkyxMaPH+8q+qoAP/bYY7H6JEiWLFlivVYfiUjz/EpxSpVLfSjCqT9GQhQYqE/Fddddd9oy9bmIa/ny5da5c2e3TYsWLVwfCZVN5YpWYtdJKWClS5e2l19+2aVbaZkCioQ6o2fLls1NAAAAQKoEFnq6ryf0Pj29VwfqO+64IzQvpToOf/XVV66PhqgVYOXKldavX79A5VI/hVdeecX27t0bsdVCnbY3bNhg5cuXj6qM6tuhSv+9994bmvfrr79actmzZ48rj4IK9fmQpUuXJtv+AQAAkL6k2HCzSsvRU3+NzKS0mwoVKti3335r8+bNcx27NeLRihUrUqQsSnWaOXOm/fTTT9a3b1/XsfnWW291y860XBoNSh22NVqUgpPNmzfb+++/71oeRClHr7/+umuB+OGHH1zqlVogRowYEXF/KodSkrSOAhulRKnMyUWd55VC9tJLL9nGjRtdJ/nwFCcAAADgnAwslF6k/hAaialw4cIuvUdpQTfddJNdccUV7gl6eCvB2aSRkTRVr17dPaXXKE6FChVyyzTC1JmUSy0y8+fPtyJFilirVq1cHwwdQ+csOl+NzqR16tSpY3Xr1rUnn3zStUpE8u9//9sGDRrkWlLUv0MtGApykov6rShoUWuN0p90LKV8AQAAAGcig3pwWzqh1hJ9P8Xq1atP64yNM6PO2+r/ceDAgSR1LAcAAEDaquvxzdsAAAAAAktTgYW+oTtXrlwRp5YtW1paomF44zvXadOmpXbxAAAAkM6kqVQojcikKRINB6tvxU4rNELU8ePHIy7Td32Ef3/F2UQqFAAAQNqVlLpeqn5BXnLTMK/xfUFdWhNfp28AAAAgNaSpVCgAAAAAqYPAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAKLNGrx4sWWIUMG279/f2oXBQAAAOkAgQUAAACAwAgsAAAAAKS/wKJJkyZ255132sCBAy1//vxWtGhRe/nll+3vv/+2W265xXLnzm3ly5e3Tz75JLTN999/by1btrRcuXK59bt06WK7d+8OLX/vvfesatWqliNHDitYsKBdffXVbn/ReO211+ySSy6xbNmyWfHixa1fv36hZdu2bbO2bdu64+bJk8c6dOhgO3fuDC1fu3atNW3a1JVZy2vVqmXffvttaPnSpUutUaNGrlylSpWy/v37xyrX0aNHbdiwYW6Zjq/zfvXVV2OVb+XKlVa7dm3LmTOn1a9f3zZs2BBatmnTJlc+XROVsU6dOrZgwYIkvR8AAADAeRlYyJQpU6xQoUL2zTffuCCjT58+duONN7qK86pVq6x58+YueDh8+LDrY3DVVVdZjRo1XKV97ty5rnKvSr7s2LHDOnbsaLfeequtX7/e9U247rrrzPO8RMvxwgsvWN++fa1Xr162bt06+/DDD13lXk6dOuUq7Xv37rXPP//cPv30U9u8ebPddNNNoe07d+5sF1xwga1YscIFAPfcc49lyZIlVOm/9tpr7frrr7fvvvvO3n77bRdohAcuXbt2tbfeesueeeYZV/YXX3zRBQjh7r33Xhs/frw798yZM7vz9B06dMhatWpln332ma1evdodr02bNi4gio+CmYMHD8aaAAAAAFWgzyuNGzf2GjZsGHp94sQJLyYmxuvSpUto3o4dOxQVeMuXL/ceeughr3nz5rH2sX37drd8w4YN3sqVK93PW7duTXJZSpQo4d17770Rl82fP9/LlCmTt23bttC8H374wR3rm2++ca9z587tTZ48OeL2PXr08Hr16hVr3pIlS7yMGTN6//zzjyu79vXpp59G3H7RokVu+YIFC0Lz5syZ4+Zp+/hccskl3oQJE+Jd/sADD7h9xJ0OHDgQ7zYAAAA4P6mOF21d77xssahWrVro50yZMrn0JaUy+ZTaI7t27XLpRosWLXJP8v3p4osvDrUKVK9e3Zo1a+a2V6uH0qr27duXaBm0799//91tG4laEJSipMlXpUoVy5cvn1smgwcPtttuu82lXo0dO9aVx6dyT548OVa5W7Ro4VpCtmzZYmvWrHHn3rhx46ivlVK1/LL7LRZDhgyxypUru3LpGCpbQi0Ww4cPtwMHDoSm7du3J3qtAAAAkPadl4GFny7k07Cq4fP0WlQJV+VZ6T2qiIdPv/zyi1155ZWucq40JfXJUMV/woQJVqlSJVd5T4j6PQT14IMP2g8//GD/+te/bOHChe74M2fOdMtU7ttvvz1WmRVsqNzlypWL+vjxXRdRUKHjjR492pYsWeKOoQDr2LFj8e5PfTnUHyR8AgAAAM7LwCIpatas6SrvZcqUcf0fwqeYmJhQhbtBgwY2cuRI19cga9asoQp+fNThWvtU/4RI1Aqgp/nhT/R//PFH1+dDAYSvYsWKNmjQIJs/f77r2zFp0qRQubV+3DJrUvkUAChAUP+NM7Vs2TLr3r27tW/f3u2vWLFitnXr1jPeHwAAANKvNB9YqHO1OlCrg7Y6SSvdaN68eW4EqZMnT9rXX3/tntirc7NSgGbMmGF//vmnCwyiaXFQx2h1nlZLgjqOq8VDlN6kyro6aGu+Opqrs7VSlzRK0z///OM6Yquz+K+//uoq+Sqff1yN9vTll1+6dfwWlg8++CDUeVtBTbdu3Vxn7FmzZrkWFu3rnXfeifraVKhQwZ2v3xrSqVOnUGsGAAAAkBRpPrAoUaKEq7QriNBoUarsa6ha9SnImDGjS+X54osv3OhIaj0YMWKECxY0PG1iVLF/6qmn7Pnnn3dDzrZu3doFAH4riAIBDYmrlCsFGmXLlnWjO4lSsPbs2eOCDR1Xo1TpmGo18ftGqDXi559/dkPOalSr+++/351P+KhUN9xwg91xxx2u30jPnj2jHiZXnnjiCVc+jaaldDH14VBLCQAAAJBUGdSDO8lbAf9Hw83mzZvXdeSmvwUAAED6reul+RYLAAAAAGcfgUUCwod6jTtpFCUAAAAA/yvz//2PCNSpOT4lS5ZM0bIAAAAA5zICiwRoaFcAAAAAiSMVCgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgMAILAAAAAIERWAAAAAAIjMACAAAAQGAEFgAAAAACI7AAAAAAEBiBBQAAAIDACCwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAAAERmABAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAAAAgsMzBd4H0zPM89//BgwdTuygAAABIZn4dz6/zJYTAAoHs2bPH/V+qVKnULgoAAADOkr/++svy5s2b4DoEFgikQIEC7v9t27YlerMhfT3dULC5fft2y5MnT2oXB+cI7gtEwn2BSLgvzh1qqVBQUaJEiUTXJbBAIBkz/m83HQUVfPARl+4J7gvExX2BSLgvEAn3xbkh2ofHdN4GAAAAEBiBBQAAAIDACCwQSLZs2eyBBx5w/wM+7gtEwn2BSLgvEAn3xfkpgxfN2FEAAAAAkABaLAAAAAAERmABAAAAIDACCwAAAACBEVggUc8995yVKVPGsmfPbldccYV98803Ca7/7rvv2sUXX+zWr1q1qn388ccpVlacm/fFyy+/bI0aNbL8+fO76eqrr070PkL6+H3hmz59umXIkMHatWt31suIc/++2L9/v/Xt29eKFy/uOu9WrFiRvyXp/J546qmnrFKlSpYjRw73xXmDBg2yI0eOpFh5ESV13gbiM336dC9r1qzea6+95v3www9ez549vXz58nk7d+6MuP6yZcu8TJkyeY8++qj3448/eiNGjPCyZMnirVu3LsXLjnPnvujUqZP33HPPeatXr/bWr1/vde/e3cubN6/322+/pXjZce7cF74tW7Z4JUuW9Bo1auS1bds2xcqLc/O+OHr0qFe7dm2vVatW3tKlS939sXjxYm/NmjUpXnacG/fEtGnTvGzZsrn/dT/MmzfPK168uDdo0KAULzsSRmCBBF1++eVe3759Q69PnjzplShRwhszZkzE9Tt06OD961//ijXviiuu8G6//fazXlaknKTeF3GdOHHCy507tzdlypSzWEqcD/eF7oX69et7r7zyitetWzcCizQoqffFCy+84JUtW9Y7duxYCpYS5/I9oXWvuuqqWPMGDx7sNWjQ4KyXFUlDKhTidezYMVu5cqVLW/FlzJjRvV6+fHnEbTQ/fH1p0aJFvOsjfdwXcR0+fNiOHz9uBQoUOIslxflwX4waNcqKFCliPXr0SKGS4ly/Lz788EOrV6+eS4UqWrSoXXrppTZ69Gg7efJkCpYc59I9Ub9+fbeNny61efNmlxrXqlWrFCs3opM5yvWQDu3evdv9Itcv9nB6/dNPP0Xc5o8//oi4vuYj/d4XcQ0bNsxKlChxWhCK9HVfLF261F599VVbs2ZNCpUS58N9oUrjwoULrXPnzq7yuHHjRrvjjjvcwwh9YRrS3z3RqVMnt13Dhg2VaWMnTpyw3r172//8z/+kUKkRLVosAKSosWPHuo66M2fOdJ32kD799ddf1qVLF9exv1ChQqldHJxDTp065VqxXnrpJatVq5bddNNNdu+999rEiRNTu2hIJYsXL3atVs8//7ytWrXKZsyYYXPmzLGHHnootYuGOGixQLz0xz5Tpky2c+fOWPP1ulixYhG30fykrI/0cV/4Hn/8cRdYLFiwwKpVq3aWS4pz+b7YtGmTbd261dq0aROrQimZM2e2DRs2WLly5VKg5DjXfl9oJKgsWbK47XyVK1d2Ld9Ko8maNetZLzfOrXvivvvucw8ibrvtNvdaI07+/fff1qtXLxd0KpUK5wbeCcRLv7z1tOizzz6L9Ydfr5X/Gonmh68vn376abzrI33cF/Loo4+6p0tz58612rVrp1Bpca7eFxqSet26dS4Nyp/+/e9/W9OmTd3PGk4S6fP3RYMGDVz6kx9oys8//+wCDoKK9HlPqF9e3ODBDzyVGoVzSBI7eyMdDgmnId4mT57sho/t1auXGxLujz/+cMu7dOni3XPPPbGGm82cObP3+OOPu2FFH3jgAYabTYOSel+MHTvWDS343nvveTt27AhNf/31VyqeBVL7voiLUaHSpqTeF9u2bXOjxvXr18/bsGGD99FHH3lFihTxHn744VQ8C6TmPaG6hO6Jt956y9u8ebM3f/58r1y5cm4kSpxbSIVCgpTb+ueff9r999/vmqEvu+wy98TZ73S1bdu2WE8RNHLDm2++aSNGjHCdqipUqGCzZs1yo3og/d4XL7zwgkthuOGGG2LtRx0xH3zwwRQvP86N+wLpQ1LvC7VWzZs3z30BmlImS5YsaQMGDHCDPiB93hOqU+gLNPX/f//7XytcuLBLo3zkkUdS8SwQSQZFFxGXAAAAAECUeHQEAAAAIDACCwAAAACBEVgAAAAACIzAAgAAAEBgBBYAAAAAAiOwAAAAABAYgQUAAACAwAgsAAAAAARGYAEAwHmge/fu1q5du9QuBgDEi2/eBgCccxXo/fv326xZs+xcs3XrVrvooots9erVdtlll6XosQ8cOGD6k50vX74UPS4ARCtz1GsCAJCOHTt2LFWPnzdv3lQ9PgAkhlQoAMA5q0mTJnbnnXfawIEDLX/+/Fa0aFF7+eWX7e+//7ZbbrnFcufObeXLl7dPPvkktM3ixYstQ4YMNmfOHKtWrZplz57d6tata99//32sfb///vt2ySWXWLZs2axMmTI2fvz4WMs176GHHrKuXbtanjx5rFevXq61QmrUqOGOofLJihUr7JprrrFChQq5AKBx48a2atWqWPvT+q+88oq1b9/ecubMaRUqVLAPP/ww1jo//PCDtW7d2h1P59aoUSPbtGlTxFSouXPnWsOGDV0LRsGCBd12/roAkBoILAAA57QpU6a4Cvs333zjgow+ffrYjTfeaPXr13eV9+bNm1uXLl3s8OHDsbYbOnSoCxZU6S9cuLC1adPGjh8/7patXLnSOnToYDfffLOtW7fOHnzwQbvvvvts8uTJsfbx+OOPW/Xq1V3qk5arDLJgwQLbsWOHzZgxw73+66+/rFu3brZ06VL76quvXNDQqlUrNz/cyJEj3XG/++47t7xz5862d+9et+y///2vXXnllS7QWbhwoSvjrbfeaidOnIh4XRRcDR482L799lv77LPPLGPGjC5oOXXqVDJefQBIAvWxAADgXNGtWzevbdu27ufGjRt7DRs2DC07ceKEFxMT43Xp0iU0b8eOHeor6C1fvty9XrRokXs9ffr00Dp79uzxcuTI4b399tvudadOnbxrrrkm1nGHDh3qValSJfS6dOnSXrt27WKts2XLFrfv1atXJ3gOJ0+e9HLnzu3Nnj07NE/bjRgxIvT60KFDbt4nn3ziXg8fPty76KKLvGPHjiV6XSL5888/3f7WrVuXYNkA4GyhxQIAcE5TOpMvU6ZMLu2natWqoXlKj5Jdu3bF2q5evXqhnwsUKGCVKlWy9evXu9f6v0GDBrHW1+tffvnFTp48GZpXu3btqMq4c+dO69mzp2upUCqUUpkOHTpk27Zti/dcYmJi3Hp+udesWeNSn7JkyRLVMVXWjh07WtmyZd1+lLolcY8JACmFztsAgHNa3Iq2+iqEz9NrORspQKr8R0NpUHv27LGnn37aSpcu7dKZFNjE7fAd6Vz8cufIkSNJZVNql46lPiclSpRw+7n00ktTvZM5gPSLFgsAQJqkvg6+ffv22c8//2yVK1d2r/X/smXLYq2v1xUrVnStIvHJmjWr+z+8VcPftn///q7fhN8hfPfu3Ukqr1ozlixZEuoHkhAFMRs2bLARI0ZYs2bN3PnoHAEgNRFYAADSpFGjRrlOzRoNSiMqqQO4P6rSXXfd5ZZp1CcFHOog/uyzz9qQIUMS3GeRIkVcy4JGZFL6k75bQpQCNXXqVJdi9fXXX7tO2UltgejXr58dPHjQdShXh2ylOmmfCiDi0ghZSgl76aWXbOPGja6ztzpyA0BqIrAAAKRJY8eOtQEDBlitWrXsjz/+sNmzZ4daHGrWrGnvvPOOTZ8+3aUP3X///S4QUQCSkMyZM9szzzxjL774oks/atu2rZv/6quvuhYD7VcjVKn1QkFIUihQUICgvhkarlblVppTpD4XGgFKZdfIUSr/oEGD7LHHHkvS8QAgufHN2wCANEXfY9G0aVNX0edbqgEg5dBiAQAAACAwAgsAAAAAgZEKBQAAACAwWiwAAAAABEZgAQAAACAwAgsAAAAAgRFYAAAAAAiMwAIAAABAYAQWAAAAAAIjsAAAAAAQGIEFAAAAgMAILAAAAABYUP8POPQBlsVeRk0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Cargar datos\n",
    "# ------------------------------------------------------------\n",
    "semanal = pd.read_csv(\"datos_semanales.csv\", parse_dates=[\"fecha\"])\n",
    "cosechas = pd.read_csv(\"datos_cosechas.csv\", parse_dates=[\"fecha_cosecha\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Ingeniería de variables ciclo a ciclo\n",
    "# ------------------------------------------------------------\n",
    "features_ciclos = []\n",
    "\n",
    "for parcela in semanal['parcela'].unique():\n",
    "    datos_parcela = semanal[semanal['parcela'] == parcela].copy()\n",
    "    datos_parcela = datos_parcela.sort_values(\"fecha\")\n",
    "    \n",
    "    ciclos = datos_parcela.groupby((datos_parcela['semana_cultivo'] == 1).cumsum())\n",
    "    \n",
    "    for i, grupo in ciclos:\n",
    "        fecha_cosecha = grupo['fecha'].max()\n",
    "        variedad = grupo['variedad'].iloc[0]\n",
    "        tam_parcela_ha = grupo['tam_parcela_ha'].iloc[0]\n",
    "        \n",
    "        temp_media = grupo['temp_media'].mean()\n",
    "        temp_std = grupo['temp_media'].std()\n",
    "        lluvia_total = grupo['lluvia'].sum()\n",
    "        fertilizante_total = grupo['fertilizante'].sum()\n",
    "        fertilizante_medio = grupo['fertilizante'].mean()\n",
    "        riego_total = grupo['riego'].sum()\n",
    "        riego_medio = grupo['riego'].mean()\n",
    "        \n",
    "        match = cosechas[\n",
    "            (cosechas['parcela'] == parcela) & \n",
    "            (cosechas['fecha_cosecha'] == fecha_cosecha)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            rendimiento = match['rendimiento_ton_ha'].iloc[0]\n",
    "            \n",
    "            features_ciclos.append({\n",
    "                \"parcela\": parcela,\n",
    "                \"variedad\": variedad,\n",
    "                \"tam_parcela_ha\": tam_parcela_ha,\n",
    "                \"temp_media\": temp_media,\n",
    "                \"temp_std\": temp_std,\n",
    "                \"lluvia_total\": lluvia_total,\n",
    "                \"fertilizante_total\": fertilizante_total,\n",
    "                \"fertilizante_medio\": fertilizante_medio,\n",
    "                \"riego_total\": riego_total,\n",
    "                \"riego_medio\": riego_medio,\n",
    "                \"rendimiento_ton_ha\": rendimiento,\n",
    "                \"mes_cosecha\": fecha_cosecha.month\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(features_ciclos)\n",
    "df['variedad_code'] = df['variedad'].astype('category').cat.codes\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Definir X e y\n",
    "# ------------------------------------------------------------\n",
    "X = df[\n",
    "    [\n",
    "        \"variedad_code\", \n",
    "        \"tam_parcela_ha\",\n",
    "        \"temp_media\", \n",
    "        \"temp_std\",\n",
    "        \"lluvia_total\", \n",
    "        \"fertilizante_total\",\n",
    "        \"fertilizante_medio\",\n",
    "        \"riego_total\", \n",
    "        \"riego_medio\", \n",
    "        \"mes_cosecha\"\n",
    "    ]\n",
    "]\n",
    "y = df[\"rendimiento_ton_ha\"]\n",
    "\n",
    "# grupos para cross-validation (usando parcela)\n",
    "groups = df[\"parcela\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Stacking Ensemble avanzado\n",
    "# ------------------------------------------------------------\n",
    "base_learners = [\n",
    "    ('xgb', xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)),\n",
    "    ('rf', RandomForestRegressor(random_state=42)),\n",
    "    ('lgb', lgb.LGBMRegressor(random_state=42))\n",
    "]\n",
    "meta_learner = Ridge()\n",
    "\n",
    "stacked = StackingRegressor(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('stack', stacked)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'stack__final_estimator__alpha': [0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=gkf.split(X, y, groups=groups),\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Entrenamiento\n",
    "# ------------------------------------------------------------\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Mejores parámetros Stacking:\")\n",
    "print(grid.best_params_)\n",
    "print(f\"Mejor R2 validación cruzada: {grid.best_score_:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. Evaluación holdout\n",
    "# ------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test, groups_train, groups_test = train_test_split(\n",
    "    X, y, groups, test_size=0.2, random_state=42\n",
    ")\n",
    "best_model = grid.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"RMSE holdout: {rmse:.2f}\")\n",
    "print(f\"R2 holdout: {r2:.2f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Importancia de variables del XGB base\n",
    "# ------------------------------------------------------------\n",
    "# sacamos la importancia del primer learner (XGB)\n",
    "booster = best_model.named_steps['stack'].estimators_[0]\n",
    "importances = booster.feature_importances_\n",
    "feat_names = X.columns\n",
    "sorted_idx = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(feat_names[sorted_idx], importances[sorted_idx], color=\"#91c7ae\")\n",
    "plt.title(\"Importancia de Variables (XGB base en Stacking)\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a3998c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado en modelo_stack.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# exportar el stacking completo\n",
    "joblib.dump(best_model, \"modelo_stack.pkl\")\n",
    "print(\"✅ Modelo guardado en modelo_stack.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7919a223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 1783.0837 - mae: 37.0164 - val_loss: 1243.7415 - val_mae: 31.0898\n",
      "Epoch 2/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1792.3549 - mae: 37.0672 - val_loss: 1211.9886 - val_mae: 30.6860\n",
      "Epoch 3/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1755.6576 - mae: 36.6978 - val_loss: 1123.9917 - val_mae: 29.6123\n",
      "Epoch 4/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1586.4000 - mae: 34.9120 - val_loss: 996.0725 - val_mae: 27.8646\n",
      "Epoch 5/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1440.0817 - mae: 33.1525 - val_loss: 876.2455 - val_mae: 25.9779\n",
      "Epoch 6/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1303.5009 - mae: 31.3179 - val_loss: 760.9543 - val_mae: 23.9622\n",
      "Epoch 7/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1188.4730 - mae: 29.6410 - val_loss: 654.6231 - val_mae: 21.9052\n",
      "Epoch 8/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1014.8557 - mae: 27.0508 - val_loss: 557.4311 - val_mae: 19.8243\n",
      "Epoch 9/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 901.0366 - mae: 25.0637 - val_loss: 469.2762 - val_mae: 17.7174\n",
      "Epoch 10/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 793.3908 - mae: 23.0326 - val_loss: 390.4493 - val_mae: 15.5898\n",
      "Epoch 11/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 681.5850 - mae: 20.8343 - val_loss: 321.2762 - val_mae: 13.5089\n",
      "Epoch 12/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 586.4272 - mae: 18.7002 - val_loss: 262.4099 - val_mae: 11.8344\n",
      "Epoch 13/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 536.4102 - mae: 17.3701 - val_loss: 214.3127 - val_mae: 10.6894\n",
      "Epoch 14/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 430.2214 - mae: 15.1233 - val_loss: 177.1093 - val_mae: 9.8961\n",
      "Epoch 15/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 353.6235 - mae: 13.5084 - val_loss: 149.6502 - val_mae: 9.3554\n",
      "Epoch 16/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 332.8469 - mae: 13.1164 - val_loss: 129.9555 - val_mae: 8.9454\n",
      "Epoch 17/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 275.0935 - mae: 12.0654 - val_loss: 117.8203 - val_mae: 8.7146\n",
      "Epoch 18/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 254.7881 - mae: 11.6717 - val_loss: 111.3589 - val_mae: 8.5909\n",
      "Epoch 19/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 219.5172 - mae: 11.0064 - val_loss: 107.9052 - val_mae: 8.5063\n",
      "Epoch 20/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 211.7816 - mae: 10.9264 - val_loss: 104.9522 - val_mae: 8.4101\n",
      "Epoch 21/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 185.5577 - mae: 10.2799 - val_loss: 99.3476 - val_mae: 8.1876\n",
      "Epoch 22/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 177.9399 - mae: 10.0284 - val_loss: 92.5584 - val_mae: 7.8838\n",
      "Epoch 23/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 167.8345 - mae: 9.6836 - val_loss: 78.8969 - val_mae: 7.2526\n",
      "Epoch 24/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 141.7943 - mae: 8.8539 - val_loss: 69.1911 - val_mae: 6.8386\n",
      "Epoch 25/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 130.7936 - mae: 8.4428 - val_loss: 55.0883 - val_mae: 6.1844\n",
      "Epoch 26/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 114.1665 - mae: 7.8588 - val_loss: 46.7870 - val_mae: 5.7188\n",
      "Epoch 27/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 106.6331 - mae: 7.5964 - val_loss: 42.6436 - val_mae: 5.4812\n",
      "Epoch 28/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 96.2787 - mae: 7.2180 - val_loss: 38.1060 - val_mae: 5.1904\n",
      "Epoch 29/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 83.5269 - mae: 6.7542 - val_loss: 37.5873 - val_mae: 5.1228\n",
      "Epoch 30/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 78.7623 - mae: 6.5801 - val_loss: 30.5838 - val_mae: 4.6340\n",
      "Epoch 31/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 74.1511 - mae: 6.3559 - val_loss: 29.0938 - val_mae: 4.4908\n",
      "Epoch 32/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 58.5205 - mae: 5.6231 - val_loss: 46.3291 - val_mae: 5.5020\n",
      "Epoch 33/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 62.3874 - mae: 5.8040 - val_loss: 32.3025 - val_mae: 4.6564\n",
      "Epoch 34/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 51.0659 - mae: 5.2637 - val_loss: 34.8728 - val_mae: 4.8060\n",
      "Epoch 35/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 53.7806 - mae: 5.4199 - val_loss: 12.6286 - val_mae: 2.9114\n",
      "Epoch 36/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 49.9292 - mae: 5.1658 - val_loss: 29.9013 - val_mae: 4.4314\n",
      "Epoch 37/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 40.3144 - mae: 4.5779 - val_loss: 17.6878 - val_mae: 3.4256\n",
      "Epoch 38/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 40.3467 - mae: 4.5085 - val_loss: 10.7384 - val_mae: 2.6125\n",
      "Epoch 39/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 38.1445 - mae: 4.5249 - val_loss: 30.0059 - val_mae: 4.4186\n",
      "Epoch 40/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 35.4262 - mae: 4.4150 - val_loss: 40.5588 - val_mae: 5.1527\n",
      "Epoch 41/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31.3180 - mae: 4.0950 - val_loss: 16.7491 - val_mae: 3.2974\n",
      "Epoch 42/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 31.8901 - mae: 4.0818 - val_loss: 12.4720 - val_mae: 2.7775\n",
      "Epoch 43/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.3134 - mae: 3.8521 - val_loss: 22.7567 - val_mae: 3.8985\n",
      "Epoch 44/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 26.6659 - mae: 3.7937 - val_loss: 17.2503 - val_mae: 3.3294\n",
      "Epoch 45/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28.4749 - mae: 3.9542 - val_loss: 45.1271 - val_mae: 5.5997\n",
      "Epoch 46/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25.7445 - mae: 3.6997 - val_loss: 9.2417 - val_mae: 2.3525\n",
      "Epoch 47/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.7670 - mae: 3.6499 - val_loss: 33.0566 - val_mae: 4.7387\n",
      "Epoch 48/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25.9412 - mae: 3.8231 - val_loss: 29.7926 - val_mae: 4.5284\n",
      "Epoch 49/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.2645 - mae: 3.5359 - val_loss: 19.4924 - val_mae: 3.6193\n",
      "Epoch 50/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23.9461 - mae: 3.5743 - val_loss: 12.2594 - val_mae: 2.7473\n",
      "Epoch 51/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21.7813 - mae: 3.4158 - val_loss: 22.9619 - val_mae: 3.9666\n",
      "Epoch 52/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 21.2223 - mae: 3.4213 - val_loss: 34.8308 - val_mae: 4.9728\n",
      "Epoch 53/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22.9077 - mae: 3.5242 - val_loss: 23.8104 - val_mae: 4.0367\n",
      "Epoch 54/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.2032 - mae: 3.0736 - val_loss: 27.2578 - val_mae: 4.3782\n",
      "Epoch 55/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16.2821 - mae: 2.9446 - val_loss: 26.1061 - val_mae: 4.2844\n",
      "Epoch 56/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.8104 - mae: 2.9225 - val_loss: 39.5911 - val_mae: 5.3223\n",
      "Epoch 57/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.7079 - mae: 3.3696 - val_loss: 45.4550 - val_mae: 5.6887\n",
      "Epoch 58/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.0788 - mae: 3.0865 - val_loss: 20.7081 - val_mae: 3.7876\n",
      "Epoch 59/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16.4204 - mae: 3.0105 - val_loss: 10.4701 - val_mae: 2.5831\n",
      "Epoch 60/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.9833 - mae: 3.0520 - val_loss: 14.5588 - val_mae: 3.1179\n",
      "Epoch 61/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.2396 - mae: 3.1677 - val_loss: 32.7652 - val_mae: 4.8562\n",
      "Epoch 62/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.2118 - mae: 3.2294 - val_loss: 40.2776 - val_mae: 5.3880\n",
      "Epoch 63/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.1142 - mae: 2.8883 - val_loss: 30.0143 - val_mae: 4.6294\n",
      "Epoch 64/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17.7790 - mae: 3.1971 - val_loss: 25.4778 - val_mae: 4.2625\n",
      "Epoch 65/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.0687 - mae: 3.0330 - val_loss: 17.9694 - val_mae: 3.5389\n",
      "Epoch 66/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.9189 - mae: 3.0573 - val_loss: 11.5091 - val_mae: 2.7594\n",
      "Epoch 67/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 13.0518 - mae: 2.7179 - val_loss: 8.6354 - val_mae: 2.3508\n",
      "Epoch 68/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 13.8664 - mae: 2.7918 - val_loss: 11.4821 - val_mae: 2.7708\n",
      "Epoch 69/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 12.2110 - mae: 2.6600 - val_loss: 11.3831 - val_mae: 2.7527\n",
      "Epoch 70/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.0549 - mae: 2.7900 - val_loss: 10.7268 - val_mae: 2.6715\n",
      "Epoch 71/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.5223 - mae: 2.8253 - val_loss: 9.6384 - val_mae: 2.5137\n",
      "Epoch 72/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.7353 - mae: 2.6175 - val_loss: 8.9820 - val_mae: 2.4207\n",
      "Epoch 73/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.0780 - mae: 2.6911 - val_loss: 11.9800 - val_mae: 2.8469\n",
      "Epoch 74/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.8949 - mae: 2.6677 - val_loss: 8.5669 - val_mae: 2.3579\n",
      "Epoch 75/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.6087 - mae: 2.7435 - val_loss: 7.5019 - val_mae: 2.2033\n",
      "Epoch 76/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.4078 - mae: 2.7328 - val_loss: 13.9097 - val_mae: 3.1074\n",
      "Epoch 77/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.5807 - mae: 2.6304 - val_loss: 17.4765 - val_mae: 3.5281\n",
      "Epoch 78/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.7618 - mae: 2.7004 - val_loss: 11.0999 - val_mae: 2.7430\n",
      "Epoch 79/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.9908 - mae: 2.5353 - val_loss: 10.5051 - val_mae: 2.6705\n",
      "Epoch 80/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.1596 - mae: 2.5361 - val_loss: 7.7945 - val_mae: 2.2529\n",
      "Epoch 81/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.2555 - mae: 2.7666 - val_loss: 7.4871 - val_mae: 2.2064\n",
      "Epoch 82/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.7123 - mae: 2.5865 - val_loss: 11.1234 - val_mae: 2.7614\n",
      "Epoch 83/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.8461 - mae: 2.6560 - val_loss: 10.0747 - val_mae: 2.6132\n",
      "Epoch 84/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.4024 - mae: 2.6852 - val_loss: 19.6138 - val_mae: 3.7655\n",
      "Epoch 85/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.2283 - mae: 2.5794 - val_loss: 15.3737 - val_mae: 3.3028\n",
      "Epoch 86/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.0241 - mae: 2.6098 - val_loss: 8.9568 - val_mae: 2.4530\n",
      "Epoch 87/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.3132 - mae: 2.4752 - val_loss: 10.9606 - val_mae: 2.7466\n",
      "Epoch 88/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.8282 - mae: 2.4461 - val_loss: 10.3157 - val_mae: 2.6689\n",
      "Epoch 89/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7147 - mae: 2.3014 - val_loss: 11.3701 - val_mae: 2.8056\n",
      "Epoch 90/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7560 - mae: 2.4552 - val_loss: 12.4310 - val_mae: 2.9543\n",
      "Epoch 91/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.6047 - mae: 2.5505 - val_loss: 15.7687 - val_mae: 3.3751\n",
      "Epoch 92/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.6824 - mae: 2.5739 - val_loss: 12.7422 - val_mae: 2.9984\n",
      "Epoch 93/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1477 - mae: 2.3838 - val_loss: 15.9465 - val_mae: 3.3922\n",
      "Epoch 94/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.2764 - mae: 2.4919 - val_loss: 11.7445 - val_mae: 2.8697\n",
      "Epoch 95/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 10.3392 - mae: 2.4497 - val_loss: 12.2265 - val_mae: 2.9306\n",
      "Epoch 96/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5059 - mae: 2.3964 - val_loss: 11.9471 - val_mae: 2.9013\n",
      "Epoch 97/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.0280 - mae: 2.4599 - val_loss: 7.9886 - val_mae: 2.3187\n",
      "Epoch 98/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.5702 - mae: 2.5290 - val_loss: 7.2897 - val_mae: 2.1962\n",
      "Epoch 99/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15.0960 - mae: 2.9613 - val_loss: 13.6214 - val_mae: 3.1136\n",
      "Epoch 100/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.5980 - mae: 2.6512 - val_loss: 14.9999 - val_mae: 3.2781\n",
      "Epoch 101/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8941 - mae: 2.3378 - val_loss: 10.7329 - val_mae: 2.7378\n",
      "Epoch 102/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5936 - mae: 2.4097 - val_loss: 9.3570 - val_mae: 2.5489\n",
      "Epoch 103/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2293 - mae: 2.3934 - val_loss: 10.8017 - val_mae: 2.7531\n",
      "Epoch 104/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3039 - mae: 2.3965 - val_loss: 11.8852 - val_mae: 2.9056\n",
      "Epoch 105/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7336 - mae: 2.3287 - val_loss: 11.0851 - val_mae: 2.7931\n",
      "Epoch 106/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5274 - mae: 2.4132 - val_loss: 10.7628 - val_mae: 2.7545\n",
      "Epoch 107/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.4454 - mae: 2.4036 - val_loss: 9.3754 - val_mae: 2.5547\n",
      "Epoch 108/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6701 - mae: 2.3828 - val_loss: 9.0364 - val_mae: 2.5065\n",
      "Epoch 109/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.8081 - mae: 2.6886 - val_loss: 12.4772 - val_mae: 2.9824\n",
      "Epoch 110/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.1127 - mae: 2.6224 - val_loss: 20.7878 - val_mae: 3.9193\n",
      "Epoch 111/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.9864 - mae: 2.5795 - val_loss: 10.6832 - val_mae: 2.7414\n",
      "Epoch 112/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6756 - mae: 2.4565 - val_loss: 11.0161 - val_mae: 2.7895\n",
      "Epoch 113/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2388 - mae: 2.3914 - val_loss: 15.8898 - val_mae: 3.4086\n",
      "Epoch 114/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3151 - mae: 2.3862 - val_loss: 10.2355 - val_mae: 2.6845\n",
      "Epoch 115/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7969 - mae: 2.3330 - val_loss: 15.9265 - val_mae: 3.4151\n",
      "Epoch 116/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.8621 - mae: 2.5773 - val_loss: 20.0228 - val_mae: 3.8625\n",
      "Epoch 117/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.3910 - mae: 2.4794 - val_loss: 14.5457 - val_mae: 3.2407\n",
      "Epoch 118/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.4648 - mae: 2.5721 - val_loss: 10.7208 - val_mae: 2.7512\n",
      "Epoch 119/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5143 - mae: 2.2995 - val_loss: 13.7045 - val_mae: 3.1421\n",
      "Epoch 120/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.6742 - mae: 2.2774 - val_loss: 7.2084 - val_mae: 2.2204\n",
      "Epoch 121/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6211 - mae: 2.4741 - val_loss: 8.6069 - val_mae: 2.4405\n",
      "Epoch 122/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5833 - mae: 2.3161 - val_loss: 13.6801 - val_mae: 3.1508\n",
      "Epoch 123/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1259 - mae: 2.3622 - val_loss: 17.8216 - val_mae: 3.6360\n",
      "Epoch 124/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.7763 - mae: 2.5354 - val_loss: 13.6117 - val_mae: 3.1478\n",
      "Epoch 125/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.0577 - mae: 2.6146 - val_loss: 15.0568 - val_mae: 3.3199\n",
      "Epoch 126/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 11.4433 - mae: 2.5433 - val_loss: 8.7182 - val_mae: 2.4708\n",
      "Epoch 127/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.1225 - mae: 2.4726 - val_loss: 7.2917 - val_mae: 2.2342\n",
      "Epoch 128/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7509 - mae: 2.4361 - val_loss: 11.1131 - val_mae: 2.8194\n",
      "Epoch 129/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1061 - mae: 2.3695 - val_loss: 10.8698 - val_mae: 2.7849\n",
      "Epoch 130/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5749 - mae: 2.2804 - val_loss: 13.1431 - val_mae: 3.0857\n",
      "Epoch 131/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8302 - mae: 2.3434 - val_loss: 11.6037 - val_mae: 2.8841\n",
      "Epoch 132/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7319 - mae: 2.3398 - val_loss: 8.6626 - val_mae: 2.4664\n",
      "Epoch 133/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9277 - mae: 2.3455 - val_loss: 10.3573 - val_mae: 2.7215\n",
      "Epoch 134/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.6434 - mae: 2.3068 - val_loss: 10.5369 - val_mae: 2.7460\n",
      "Epoch 135/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3306 - mae: 2.2357 - val_loss: 15.5175 - val_mae: 3.3892\n",
      "Epoch 136/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6996 - mae: 2.4100 - val_loss: 8.5953 - val_mae: 2.4552\n",
      "Epoch 137/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5290 - mae: 2.2598 - val_loss: 9.6421 - val_mae: 2.6154\n",
      "Epoch 138/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.4689 - mae: 2.2504 - val_loss: 9.7670 - val_mae: 2.6431\n",
      "Epoch 139/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.6951 - mae: 2.3231 - val_loss: 11.3177 - val_mae: 2.8555\n",
      "Epoch 140/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3645 - mae: 2.2669 - val_loss: 9.9770 - val_mae: 2.6723\n",
      "Epoch 141/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7977 - mae: 2.3226 - val_loss: 8.3374 - val_mae: 2.4167\n",
      "Epoch 142/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9205 - mae: 2.3347 - val_loss: 13.4575 - val_mae: 3.1435\n",
      "Epoch 143/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9536 - mae: 2.3343 - val_loss: 10.9384 - val_mae: 2.8038\n",
      "Epoch 144/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.2152 - mae: 2.2567 - val_loss: 10.1950 - val_mae: 2.7029\n",
      "Epoch 145/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.2768 - mae: 2.2802 - val_loss: 10.0713 - val_mae: 2.6852\n",
      "Epoch 146/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0014 - mae: 2.2328 - val_loss: 10.6947 - val_mae: 2.7748\n",
      "Epoch 147/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8009 - mae: 2.3081 - val_loss: 10.1873 - val_mae: 2.7057\n",
      "Epoch 148/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1409 - mae: 2.2289 - val_loss: 8.9439 - val_mae: 2.5214\n",
      "Epoch 149/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.0484 - mae: 2.4622 - val_loss: 7.9725 - val_mae: 2.3587\n",
      "Epoch 150/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7460 - mae: 2.4469 - val_loss: 8.0061 - val_mae: 2.3601\n",
      "Epoch 151/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7724 - mae: 2.1827 - val_loss: 9.3306 - val_mae: 2.5800\n",
      "Epoch 152/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1862 - mae: 2.3992 - val_loss: 12.7304 - val_mae: 3.0430\n",
      "Epoch 153/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.4286 - mae: 2.3771 - val_loss: 10.3943 - val_mae: 2.7359\n",
      "Epoch 154/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3196 - mae: 2.2403 - val_loss: 10.7260 - val_mae: 2.7821\n",
      "Epoch 155/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9679 - mae: 2.2218 - val_loss: 11.2012 - val_mae: 2.8479\n",
      "Epoch 156/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9037 - mae: 2.1982 - val_loss: 8.9048 - val_mae: 2.5173\n",
      "Epoch 157/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9952 - mae: 2.2437 - val_loss: 9.9934 - val_mae: 2.6831\n",
      "Epoch 158/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.5649 - mae: 2.4432 - val_loss: 7.7217 - val_mae: 2.3223\n",
      "Epoch 159/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2846 - mae: 2.2645 - val_loss: 7.8563 - val_mae: 2.3447\n",
      "Epoch 160/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.1639 - mae: 2.3728 - val_loss: 10.3280 - val_mae: 2.7306\n",
      "Epoch 161/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8781 - mae: 2.1746 - val_loss: 10.6533 - val_mae: 2.7775\n",
      "Epoch 162/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.6056 - mae: 2.3696 - val_loss: 10.6470 - val_mae: 2.7778\n",
      "Epoch 163/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2762 - mae: 2.2811 - val_loss: 8.6142 - val_mae: 2.4739\n",
      "Epoch 164/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1803 - mae: 2.2790 - val_loss: 8.8456 - val_mae: 2.5113\n",
      "Epoch 165/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3883 - mae: 2.3052 - val_loss: 13.0266 - val_mae: 3.0903\n",
      "Epoch 166/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1591 - mae: 2.4031 - val_loss: 13.4688 - val_mae: 3.1466\n",
      "Epoch 167/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9723 - mae: 2.3679 - val_loss: 10.1792 - val_mae: 2.7081\n",
      "Epoch 168/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.6517 - mae: 2.3421 - val_loss: 8.1707 - val_mae: 2.3953\n",
      "Epoch 169/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5270 - mae: 2.2885 - val_loss: 7.4869 - val_mae: 2.2862\n",
      "Epoch 170/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 10.0881 - mae: 2.5009 - val_loss: 6.5853 - val_mae: 2.1456\n",
      "Epoch 171/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7331 - mae: 2.4197 - val_loss: 8.0079 - val_mae: 2.3781\n",
      "Epoch 172/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.4523 - mae: 2.4040 - val_loss: 10.0364 - val_mae: 2.6861\n",
      "Epoch 173/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.4615 - mae: 2.3027 - val_loss: 16.2510 - val_mae: 3.4729\n",
      "Epoch 174/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3911 - mae: 2.2530 - val_loss: 9.3055 - val_mae: 2.5799\n",
      "Epoch 175/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.8500 - mae: 2.2138 - val_loss: 11.1817 - val_mae: 2.8468\n",
      "Epoch 176/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3066 - mae: 2.2864 - val_loss: 9.5841 - val_mae: 2.6240\n",
      "Epoch 177/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9220 - mae: 2.2093 - val_loss: 10.0652 - val_mae: 2.6957\n",
      "Epoch 178/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9952 - mae: 2.2011 - val_loss: 12.3817 - val_mae: 3.0073\n",
      "Epoch 179/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2160 - mae: 2.3867 - val_loss: 7.8886 - val_mae: 2.3568\n",
      "Epoch 180/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1842 - mae: 2.2464 - val_loss: 8.6677 - val_mae: 2.4805\n",
      "Epoch 181/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3921 - mae: 2.1429 - val_loss: 10.0544 - val_mae: 2.6936\n",
      "Epoch 182/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4609 - mae: 2.1542 - val_loss: 7.4267 - val_mae: 2.2776\n",
      "Epoch 183/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8950 - mae: 2.3489 - val_loss: 11.9349 - val_mae: 2.9551\n",
      "Epoch 184/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7671 - mae: 2.3307 - val_loss: 11.4118 - val_mae: 2.8812\n",
      "Epoch 185/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7612 - mae: 2.2039 - val_loss: 8.3343 - val_mae: 2.4286\n",
      "Epoch 186/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0942 - mae: 2.2641 - val_loss: 7.9813 - val_mae: 2.3684\n",
      "Epoch 187/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6556 - mae: 2.1784 - val_loss: 10.4738 - val_mae: 2.7558\n",
      "Epoch 188/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1290 - mae: 2.2437 - val_loss: 7.0851 - val_mae: 2.2247\n",
      "Epoch 189/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3455 - mae: 2.3011 - val_loss: 9.1705 - val_mae: 2.5645\n",
      "Epoch 190/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1753 - mae: 2.2633 - val_loss: 11.0834 - val_mae: 2.8392\n",
      "Epoch 191/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.6686 - mae: 2.1610 - val_loss: 9.7423 - val_mae: 2.6463\n",
      "Epoch 192/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.4258 - mae: 2.2589 - val_loss: 7.8292 - val_mae: 2.3450\n",
      "Epoch 193/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8430 - mae: 2.1715 - val_loss: 9.7099 - val_mae: 2.6451\n",
      "Epoch 194/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9514 - mae: 2.3637 - val_loss: 9.7382 - val_mae: 2.6432\n",
      "Epoch 195/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2802 - mae: 2.2906 - val_loss: 6.3640 - val_mae: 2.0994\n",
      "Epoch 196/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1048 - mae: 2.3164 - val_loss: 11.0999 - val_mae: 2.8344\n",
      "Epoch 197/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5647 - mae: 2.3147 - val_loss: 11.5956 - val_mae: 2.9013\n",
      "Epoch 198/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9248 - mae: 2.1680 - val_loss: 16.2797 - val_mae: 3.4825\n",
      "Epoch 199/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.0030 - mae: 2.2524 - val_loss: 10.5354 - val_mae: 2.7557\n",
      "Epoch 200/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0448 - mae: 2.2544 - val_loss: 7.0229 - val_mae: 2.2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LSTM secuencial guardado en modelo_lstm_semanal.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# cargar semanal\n",
    "df = pd.read_csv(\"datos_semanales.csv\", parse_dates=[\"fecha\"])\n",
    "df_cosechas = pd.read_csv(\"datos_cosechas.csv\", parse_dates=[\"fecha_cosecha\"])\n",
    "\n",
    "features = [\"temp_media\", \"lluvia\", \"fertilizante\", \"riego\"]\n",
    "\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "for parcela in df[\"parcela\"].unique():\n",
    "    datos_parcela = df[df[\"parcela\"] == parcela].sort_values(\"fecha\")\n",
    "    ciclos = datos_parcela.groupby((datos_parcela['semana_cultivo'] == 1).cumsum())\n",
    "\n",
    "    for _, grupo in ciclos:\n",
    "        seq = grupo[features].values\n",
    "        if len(seq) < 12:\n",
    "            continue\n",
    "        seq = seq[:12]\n",
    "        \n",
    "        # generar el target como rendimiento acumulado simulado por semana\n",
    "        cosecha = df_cosechas[\n",
    "            (df_cosechas[\"parcela\"] == parcela) &\n",
    "            (df_cosechas[\"fecha_cosecha\"] == grupo[\"fecha\"].max())\n",
    "        ]\n",
    "        if not cosecha.empty:\n",
    "            total_rend = cosecha[\"rendimiento_ton_ha\"].iloc[0]\n",
    "            # distribuimos de forma lineal como ejemplo\n",
    "            y_vector = np.linspace(total_rend/12, total_rend, 12)\n",
    "            X_seq.append(seq)\n",
    "            y_seq.append(y_vector)\n",
    "\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# normalizar\n",
    "scaler = MinMaxScaler()\n",
    "n_samples, n_steps, n_features = X_seq.shape\n",
    "X_seq_reshape = X_seq.reshape(-1, n_features)\n",
    "X_seq_norm = scaler.fit_transform(X_seq_reshape)\n",
    "X_seq_norm = X_seq_norm.reshape(n_samples, n_steps, n_features)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# modelo LSTM\n",
    "# --------------------------------------------------\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(64, input_shape=(12, len(features)), return_sequences=True),\n",
    "    layers.TimeDistributed(layers.Dense(16, activation=\"relu\")),\n",
    "    layers.TimeDistributed(layers.Dense(1))\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(\n",
    "    X_seq_norm, y_seq.reshape(n_samples, n_steps, 1),\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "model.save(\"modelo_lstm.h5\")\n",
    "print(\"✅ LSTM secuencial guardado en modelo_lstm_semanal.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
